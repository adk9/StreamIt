\section{General {\StreamIt} Scheduling Concepts}
\label{chpt:sched-basic}

This chapter introduces the general concepts used for scheduling
{\StreamIt} programs.  Concepts presented here are are common with
other languages \cite{ptolemyoverview} \cite{esterel92}
\cite{lustre}.

Section \ref{sec:exec-model} presents the {\StreamIt} execution
model. Section \ref{sec:steady-state} introduces the concept of a
steady state and shows how to calculate it. Section
\ref{sec:init-peeking} explains the need for initialization of
{\StreamIt} program. Section \ref{sec:general:schedules} introduces
simple notation for expressing schedules while Section
\ref{sec:sched-vs-buffer} presents the tradeoff between schedule
and buffer storage requirements.

\subsection{{\StreamIt} execution model}
\label{sec:exec-model}

A {\StreamIt} program is represented by a directed graph, $G = (N,
E)$.  A node in $G$ is either a {\filter}, a {\splitter} or a
{\joiner}. Edges in $G$ represent data {\Channels}.  Each node in
$G$ takes data from its {\Input} {\Channel}(s), processes this data,
and puts the result on the {\Output} {\Channel}(s).  Each data
{\Channel} is simply a FIFO queue.

Each {\filter} node $n_f$ has exactly one incoming edge and one
outgoing edge.  The incoming edge is referred to as an {\Input}
{{\Channel}}, while the outgoing edge is called an {\Output}
{{\Channel}}. A {\splitter} node $n_s$ has exactly one incoming edge
({\Input} {\Channel}), but has multiple outgoing edges ({\Output}
{\Channels}). A {\joiner} node has multiple incoming edges ({\Input}
{\Channels}) but only one outgoing edge ({\Output} {\Channel}).

Each node of graph $G$ can be executed.  An execution of a node
causes some data to be collected from the node's {\Input}
{\Channel}(s), the data to be processed and the result to be put on
the {\Output} {\Channel}(s).  An execution of a node transfers the
smallest amount of data across the node - it is an atomic
operation.  {\StreamIt} uses a static data flow model, meaning
that every execution of a node $n$ will require the same amount of
data to be present on node's {\Input} {\Channel}(s) for consumption or
inspection, same amount to be consumed from the {\Input} {\Channel}(s)
and same amount of data to be pushed onto its {\Output} {\Channel}(s).

Each {\filter} node $n_f$ is associated with a 3-tuple $(e_f, o_f,
u_f)$. These three values represent the rate of data flow for the
{\filter} for each execution.  The first value represents the
amount of data necessary to be present in its {\Input} {\Channel} in
order to execute the {\filter}.  This is also called the peek
amount of the {\filter}.  The second value represents the amount
of data which will be consumed by the {\filter} from its {\Input}
{\Channel}. This is called the pop amount of the {\filter}.  Note,
that $e_f \ge o_f$. The final value represents the amount of data
that will be put on the {\Output} {\Channel} of the {\filter}. This is
called the push amount of a {\filter}.  The amount of data present
in the {\Input} {{\Channel}} of a {\filter} node $n_f$ is denoted
$in_f$, while data present in the {\Output} {{\Channel}} is denoted
$out_f$.

Each {\splitter} node $n_s$ is associated with a tuple $(o_s,
w_s)$. The first value represents the amount amount of data that
will be consumed by $n_s$ from its {\Input} {\Channel}. Thus, in order
to execute $n_s$, there must be at least $o_s$ data in its {\Input}
{\Channel}. $w_s$ is a vector of integers, each representing the
amount of data that will be pushed onto a corresponding {\Output}
{\Channel} of $n_s$.  The amount of data present in the {\Input}
{{\Channel}} of a {\splitter} node $n_s$ is denoted $in_s$, while
data present in the $i$th {\Output} {{\Channel}} is denoted
$out_{s,j}$.

Each {\joiner} node $n_j$ is associated with a tuple $(w_j, u_j)$.
The first value is a vector of integers, each representing the
amount of data that will be consumed by $n_j$ from its
corresponding {\Input} {\Channels}.  In order to execute $n_j$, each
of its {\Input} {\Channels} must have at least as much data in it as
the corresponding value in $w_j$ indicates.  $u_j$ represents the
amount of data that will be pushed by $n_j$ onto its {\Output}
{\Channel}. The amount of data present in the $i$th {\Input}
{{\Channel}} of a {\joiner} node $n_j$ is denoted $in_{j,i}$, while
data present in the {\Output} {{\Channel}} is denoted $in_s$.

A schedule for a {\StreamIt} program is a list of executions of
nodes of graph $G$.  The list describes the order in which these
nodes are to be executed.  In order for a schedule to be legal, it
must satisfy two conditions.  The first one is that for every
execution of a node, a sufficient amount of data must be present
on its {\Input} {\Channel}(s), as described above.  The second is that
the execution of the schedule must require a finite amount of
memory.

\subsection{Steady State}
\label{sec:steady-state}

A {\StreamIt} schedule is an ordered list of firings of nodes in the
{\StreamIt} graph.  Every firing of a node consumes some data from
{\Input} {{\Channel}}(s) and pushes data onto the {\Output} {{\Channel}}(s).

One of the most important concepts in scheduling streaming
applications is the steady state schedule.  A steady state
schedule is a schedule that the program can repeatedly execute
forever.  It has a property that the amount of data buffered up
between any two nodes does not change from before to after the
execution of the steady state schedule.  This property is
important, because it allows the compiler to statically schedule
the program at compile time, and simply repeat the schedule
forever at runtime.  A schedule without this property cannot be
repeated continuously.  This is because the delta in amount of
data buffered up on between nodes will continue accumulating,
requiring an infinite amount of buffering space.

A steady state of a program is a collection of number of times
that every node in the program needs to execute in a steady state
schedule.  It does not impose an order of execution of the nodes
in the program.

Not every {\StreamIt} program has a steady state schedule.  As will
be explained in Section \ref{sec:calc-min-steady}, it is possible
for a program to have unbalanced production and consumption of
data in {\splitjoins} and {\feedbackloops}.  The amount of data
buffered continually increases, and cannot be reduced, thus making
it impossible to create a steady state schedule for them.  It is
also possible that a {\feedbackloop} does not have enough data
buffered up internally in order to complete execution of a full
steady state, and thus deadlocks. Programs without a valid steady
state schedule are not considered valid {\StreamIt} programs. In
other words, all valid {\StreamIt} programs have a steady state
schedule.

\subsubsection{Minimal Steady State}

The size of a steady state is defined as the sum of all executions
of all the nodes in the program per iteration of the steady state.

\begin{definition}
A steady state of stream $s$ is represented by vector $m$ of
non-negative integers. Each of the elements in $m$ represents the
number of times a corresponding node in $s$ must be executed in
the steady state.
\end{definition}

Note that $m$ does not impose an order of execution of nodes. Size
of a steady state is the total number of executions of all the
nodes in the steady state, and is represented by $\sum_i m_i$.

Next we will summerize the properties of schedules prsented in
\cite{lee87static}.

\begin{theorem}[Minimal Steady State Uniqueness]
A {\StreamIt} program that has a valid steady state, has a unique
minimal steady state.
\end{theorem}

\begin{proof}[Minimal Steady State Uniqueness]
Assume that there are two different minimal steady states with
same size.  Let $m$ and $q$ denote vectors representing the two
steady states. Let $\sum_i m_i$ denote size of schedule $m$ and
$\sum_i q_i$ denote size of schedule $q$. Note that since both $m$
and $q$ are minimal steady states, $\sum_i m_i = \sum_i q_i$.
Since the schedules are different, there must be some $j$ for
which $m_j \ne q_j$. Assume without loss of generality that $m_j <
q_j$. Since a steady state does not change the amount of data
buffered between nodes, the node producing data for node $i$ must
also execute less times than corresponding node in $q$. Similarly,
the node consuming data produced by node $j$ also must execute
less times than the corresponding node in schedule $q$. Since a
{\StreamIt} program describes a connected graph, it follows that
$\forall i, m_i < q_i$.  Thus $\sum_i m_i \ne \sum_i q_i$, which
is a contradiction. Thus there cannot be two different minimal
steady state.
\end{proof}

\begin{corollary}[Minimal Steady State Uniqueness]
\label{corollary:minimal-state}
The additional property we have from the above proof is that if
$m$ represents a minimal steady and $q$ any other steady state,
then $\forall i, m_i < q_i$.
\end{corollary}

\begin{lemma}[Composition of Steady Schedules]
\label{lemma:composition}
If $m$ and $q$ are two steady states for a {\StreamIt} program, then
$m + q$ is also a steady state.
\end{lemma}

The above lemma is true because neither $m$ nor $q$ change the
amount of data buffered in the {{\Channels}}.  Thus a composition of
the steady states does not change the amount of data buffered in
the {{\Channels}}, which makes the composition also a steady schedule.

\begin{corollary}[Composition of Steady Schedules]
\label{corollary:composition}
If $m$ and $q$ are two steady states, and $\forall i, m_i > q_i$,
then $w = m - q$ is also a steady state.
\end{corollary}

If $q$ is a steady state and $m = w + q$ is a steady state, then
$w$ must not change the amount of data buffered in {{\Channels}}. Thus
$w$ must be a steady state.

\begin{theorem}[Multiplicity of Minimal Steady States]
If a {\StreamIt} program has a valid steady state, then all its
steady states are strict multiples of its minimal steady state.
\label{thm:multiplicity}
\end{theorem}

\begin{proof}[Multiplicity of Minimal Steady State]
Assume that there exists a steady state that is not a multiple of
the minimal steady state.  Let $m$ denote the minimal steady
state. Let $q$ denote the other steady state.  Note that $w = q -
m$ is still a steady state, as long as all elements of $w$ remain
non-negative (by Corollary \ref{corollary:composition}).  Repeat
subtracting $m$ from $q$ until no more subtractions can be
performed without generating at least one negative element in
vector $w$.  Since $q$ is not a multiple of $m$, $w \ne 0$. But
since we cannot subtract $m$ from $w$ any further, $\exists i, m_i
> w_i$.  Since $m$ is a minimal steady state and $w$ is a steady
state, this is impossible due to Corollary
\ref{corollary:minimal-state}. Thus there are no steady states
that are not multiples of the minimal steady schedule.
\end{proof}

\subsubsection{Calculating Minimal Steady State}
\label{sec:calc-min-steady}

This section presents equations used for calculating minimal
steady states.  Minimal steady states are calculated recursively
in a hierarchical manner. That is, a minimal steady state is
calculated for all children streams of {\pipeline}, {\splitjoin} and
{\feedbackloop}, and then the schedule is computed for the actual
parent stream using these minimal states as atomic executions.
This yields a minimal steady state because all child streams must
execute their steady states (to avoid buffering changes), and all
steady states are multiples of the minimal steady states (per
Theorem \ref{thm:multiplicity}).  Executing a full steady state of
a stream is referred to as "executing a stream".

\subsubsubsection{Notation of Steady States}

In this section, the notation for $peek$, $pop$ and $push$ will be
extended to mean entire streams in their minimal steady state
execution.  That is, a {\pipeline} $p$ will consume $o_p$ data,
produce $u_p$ data and peek $e_p$ data on every execution of its
steady state.  Again, in the hierarchical view of {\StreamIt}
programs, a child stream of a {\pipeline} will execute its steady
state atomically.

A steady state of a stream $s$ is represented by a set $S_s$ of
elements, $S_s = \{m, N, c, v\}$. The set includes a vector $m$,
which describes how many times each {\StreamIt} node of the stream
will be executed in the steady state, a corresponding ordered set
$N$ which stores all the nodes of the stream, a vector $c$, which
holds values $[e_s, o_s, u_s]$ for stream $s$, and a vector $v$
which holds number of steady state executions of all direct
children of $s$. $m$ and $v$ are not the same vector, because $m$
refers to nodes in the subgraph, while $v$ refers only to the
direct children, which may be {\filters}, {\pipelines},
{\splitters} and {\feedbackloops}.

For a stream $s$, set $S$ is denoted as $S_s$ and the elements of
$S_s$ are denoted as $S_{s,m}$, $S_{s,N}$, $S_{s,c} and S_{s,v}$.

Note, that a steady state does not say anything about the ordering
of the execution of nodes, only how many times each node needs to
be executed to preserve amount of data buffered by the stream.

\begin{figure}
\begin{center}

\begin{minipage}{1.5in}
\centering \psfig{figure=pipeline-steady-state.eps,width=0.6in} \\
{\protect\small (a) A sample {\pipeline}}
\end{minipage}
~
\begin{minipage}{1.5in}
\centering \psfig{figure=splitjoin-steady-state.eps,width=1.2in} \\
{\protect\small (b) A sample {\splitjoin}}
\end{minipage}
~
\begin{minipage}{2in}
\centering \psfig{figure=feedback-steady-state.eps,width=1.0in} \\
{\protect\small (c) A sample {\feedbackloop}.  The $L$ {\filter} has
been flipped upside-down for clarity.\\$peek_L = pop_L = 5, push_L
= 6$}
\end{minipage}

\caption{Sample {\StreamIt} streams} \label{fig:steady-state}

\end{center}
\end{figure}

\subsubsubsection{\filter}

Since {\filters} do not have any internal buffering, their minimal
steady state is to execute the {\filter}'s {\work} function once. This
is the smallest amount of execution a {\filter} can have.

Thus, for a {\filter} $f$,

\begin{displaymath}
S_f = \left\{[1], \{f\}, { \left[
\begin{array}{c}e_f\\o_f\\u_f
\end{array}
\right]}, [] \right\}
\end{displaymath}

Notice that $S_{f,v}$ is empty, because a {\filter} does not have
any children.

\subsubsubsection{\pipeline}

Let the {\pipeline} $p$ have $n$ children and let $p_i$ denote
the $i$th child of the {\pipeline} (counting from {\Input} to
{\Output}, starting with 0, the children may be streams, not
necessarily {\filters}). We must find $S_p$.

We start with calculating all $S_{p_i}, i \in \{0, \dots, n-1\}$.
This task is achieved recursively.

Next we find a fractional vector $v''$ such that executing each
$p_i$ $v_i''$ times will not change the amount of data buffered in
the {\pipeline} and the first child is executed exactly once.  Since
the children streams are executed fractional amount of times, we
calculate the amount of data they produce and consume during this
execution by multiplying $S_{p_i,c_o}$ and $S_{p_i,c_u}$ by
$v_i''$. Thus $v''$ must have the following property

\begin{displaymath}
v_0'' = 1, \forall i \in \{0,\dots,n-1\}, v_i'' * u_{p_i} =
v_{i+1}'' * o_{p_{i-1}}
\end{displaymath}

We compute $v''$ as follows.  The first child executes once, thus
$v_0'' = 1$.  The second child must execute $v_1'' = {u_{p_0}
\over {o_{p_1}}}$ times to ensure that all data pushed on the the
first {{\Channel}} is consumed by the second child.  The third child
must execute $v_2'' = v_1'' {u_{p_1} \over o_{p_2}} = {u_{p_0}
\over o_{p_1}} {u_{p_1} \over o_{p_2}}$ times to ensure that it
consumes all the data produced by the second child. Thus,

\begin{displaymath}
v_i'' = {\prod_{j = 0}^{i-1} u_{p_j} \over \prod_{j=1}^i o_{p_j}}
\end{displaymath}

Next we will find an integral vector $v'$ such that executing each
$p_i$ $v_i'$ times will not change the amount of data buffered in
the {\pipeline}.  $v'$ will be a valid steady state of the
{\pipeline}.

In order to calculate $v'$ we multiply $v''$ by $\prod_{j=1}^{n-1}
o_{p_j}$.  Thus

\begin{displaymath}
v'_i = \left({\prod_{j = 0}^{i-1} u_{p_j} \over \prod_{j=1}^i
o_{p_j}} \right) \left(\prod_{j=1}^{n-1} o_{p_j} \right) = \left(
\prod_{j=0}^{i-1} u_{p_j} \right) \left( \prod_{j=i+1}^{n-1}
o_{p_j} \right)
\end{displaymath}

Now we find an integral vector $v$, such that, for some positive
integer $g$, $v' = g * v$, and $\sum_i v_i$ is minimal.  In other
words, we find the greatest integer $g$, such that $v' = g * v$,
with $v$ consisting of integers.  $v$ represents the minimal
steady state for pipeline $p$.

This is achieved by finding the $\gcd$ of all elements in $v'$,
and dividing $v'$ by $g$.  Thus

\begin{displaymath}
v = {v' \over \gcd(v')}
\end{displaymath}

$v$ represents the number of times each child of $p$ will need to
execute its steady state in order to execute the minimal steady
state of $p$, thus $S_{p,v} = v$.  $v$ holds a steady state
because amount of data buffered in $p$ does not change, and it is
a minimal steady state, because $\sum_i v_i$ is minimal.

We construct set $S_p$ as follows:\footnote{Here we use symbol
$\circ$ to denote concatenation of vectors and sets.  Thus $[1\ 2\
3] \circ [4\ 5\ 6] = [1\ 2\ 3\ 4\ 5\ 6]$ and $\{A\ B\ C\} \circ
\{D\ E\ F\} = \{A\ B\ C\ D\ E\ F\}$.}

\begin{displaymath}
S_p = \left\{ \begin{array}{c}
v_0 * S_{p_0,m} \circ \dots \circ
v_{n-1}
* S_{p_{n-1}, m}, S_{p_0, N} \circ \dots \circ S_{P_{n-1}, N}, \\
\left[
\begin{array}{c}
e_{p_0} + (v_0 - 1) * o_{p_0} \\
v_0 * o_{p_0} \\
v_{n-1} * u_{p_{n-1}}
\end{array}\right], v \end{array} \right\}
\end{displaymath}

An example is presented in Figure \ref{fig:steady-state} (a). For
this {\pipeline}, we have the following steady states for all
children of the {\pipeline}:

\begin{displaymath}
\begin{array}{lrlr}
S_A = & \left\{[1], \{A\}, { \left[
\begin{array}{c} 1 \\ 1 \\ 3
\end{array}
\right]}, [] \right\}, &

S_B = & \left\{[1], \{B\}, { \left[
\begin{array}{c} 3 \\ 2 \\ 3
\end{array}
\right]}, [] \right\} \\ \\

S_C = & \left\{[1], \{D\}, { \left[
\begin{array}{c} 2 \\ 2 \\ 1
\end{array}
\right]}, [] \right\}, &

S_D = & \left\{[1], \{D\}, { \left[
\begin{array}{c} 5 \\ 3 \\ 1
\end{array}
\right]}, [] \right\} \\

\end{array}
\end{displaymath}

Using the steady states above, we get the following vector $v'$:

\begin{displaymath}
v' = \left[
\begin{array}{c}
(2 * 2 * 3)\\
(3) (2 * 3) \\
(3 * 3) (3) \\
(3 * 3 * 1)
\end{array}
\right] = \left[
\begin{array}{c}
12\\ 18\\ 27\\ 9
\end{array}
\right]
\end{displaymath}

We now calculate $g = \gcd(v') = \gcd(12,18,27,9) = 3$.  We thus
have

\begin{displaymath}
v = {v' \over 3} = {1 \over 3} \left[
\begin{array}{c}
12\\ 18\\ 27\\ 9
\end{array}
\right] = \left[
\begin{array}{c}
4\\ 6\\ 9\\ 3
\end{array}
\right]
\end{displaymath}

Finally, we construct $S_p$:

\begin{displaymath}
S_p = \left\{
\begin{array}{c}
4 S_{A,m} \circ 6 S_{B,m} \circ 9 S_{C,m} \circ 3
S_{D,m}, S_{A,N} \circ S_{B,N} \circ S_{C,N} \circ S_{D,N} \\
\left[
\begin{array}{c}
1 + (4-1) * 1 \\
4 * 1 \\
3 * 1
\end{array}\right],
\left[ \begin{array}{c} 4\\ 6\\ 9\\ 3 \end{array}
\right]
\end{array}
\right\}
\end{displaymath}

\subsubsubsection{\splitjoin}

Let the {\splitjoin} have $n$ children and let $sj_i$ denote the
$i$th child of the {\splitjoin} (counting from left to right,
starting with 0).  Let $sj_s$ and $sj_j$ denote the {\splitter} and
the {\joiner} of the {\splitjoin}, respectively. Let $w_{s,i}$ denote
the number of items sent by the {\splitter} to $i$th child on
{\splitter}'s every execution. Let $w_{j,i}$ denote the number of
items consumed by the {\joiner} from the $i$th child on {\joiner}'s
every execution.  We are computing $S_{sj}$.

We start by calculating all $S_{sj_i}, i \in \{0, \dots, n-1\}$.

Next we compute a fraction vector $v''$ and a fraction $a_j''$
such that executing the {\splitter} exactly once, each child $sj_i$
$v_i''$ times and the {\joiner} $a_j''$ times does not change the
amount of data buffered in the {\splitjoin}. Again, since $v''$ and
$a_j''$ are fractions, we multiply the steady-state pop and push
amounts by appropriate fractions to obtain the amount of data
pushed and popped.  For convenience we define $a_s''$ to be the
number of executions of the {\splitter} and set it to 1.

\begin{comment}
\begin{displaymath}
v'', a_j'', a_s'' \ne 0, \forall i \in \{0,\dots,n-1\}, a_s'' *
w_{s, i} = v_i'' * o_{sj_i}, v_i'' * u_{sj_i} = a_j'' * w_{j, i}
\end{displaymath}
\end{comment}

We thus have that each child $sj_i$ must execute $v_i'' = {w_{s,i}
\over o_{sj_i}}$ times. To compute the number of executions of the
{\joiner}, $a_j''$, we select an arbitrary $k$th child ($0 \le k <
n$) and have that the {\joiner} executes $a_j'' = {{w_{s,k} \over
o_{s_k}}{u_{sj_k} \over w_{j,k}}}$ times.

Next we compute integer vector $v'$ and integers $a_s$ and $a_j$
such that executing the {\splitter} $a_s$ times, each child $sj_i$
$v_i'$ times and the {\joiner} $a_j$ times still does not change the
amount of data buffered in the {\splitjoin}. We do this by
multiplying $a_s''$, $v''$ and $a_j''$ by $w_{j,k}
\left(\prod_{r=0}^{n-1}o_{sj_r}\right)$. Thus we get

\begin{displaymath}
\begin{array}{rl}
a_s' = & w_{j,k} \left(\prod_{r=0}^{n-1}o_{sj_r}\right) \\
v_i' = & w_{j,k} \left(\prod_{r=0}^{n-1}o_{sj_r}\right) * {w_{s,i}
\over o_{sj_i}} = w_{s,i} * w_{j_k} \left( \prod_{r=0}^{i-1}
o_{s_r} \right) \left( \prod_{r=i+1}^{n-1} o_{s_r} \right)
\\
a_j' = & w_{j,k} \left(\prod_{r=0}^{n-1}o_{sj_r}\right) *
{{w_{s,k} \over o_{s_k}}{u_{sj_k} \over w_{j,k}}} = w_{s,k} *
u_{sj_k} * \left( \prod_{r=0}^{k-1} o_{s_r} \right)
\left( \prod_{r=k+1}^{n-1} o_{s_r} \right) \\
\end{array}
\end{displaymath}

Now we use $v'$, $a_s'$ and $a_j'$ to compute minimal steady state
of the {\splitjoin}.  Since $v'$, $a_s'$ and $a_j'$ represent a
steady state, they represent a strict multiple of the minimal
steady state.  Thus we find the multiplier by computing $g$, the
$\gcd$ of all elements in $v'$ and integers $a_s'$ and $a_j'$, and
dividing $v'$, $a_s'$ and $a_j'$ by $g$.  We have that

\begin{displaymath}
\begin{array}{rl}
g = & \gcd(v', a_s', a_j') \\
v = & v' \over g \\
a_s = &  a_s' \over g \\
a_j = & a_j' \over g
\end{array}
\end{displaymath}

Finally, we use $v$, $a_s$ and $a_j$ to construct $S_{sj}$:

\begin{displaymath}
S_{sj} = \left\{
\begin{array}{c}
v_0 * S_{sj_0,m} \circ \dots \circ v_{n-1} * S_{sj_{n-1}, m} \circ
[a_s\ a_j] , \\
S_{sj_0, N} \circ \dots \circ S_{sj_{n-1}, N} \circ \{sj_s,
sj_j\},
\\ \left[
\begin{array}{c}
n_s * o_{s} \\
n_s * o_{s} \\
n_j * u_{j} \\
\end{array}\right], \\
v \circ [a_s] \circ [a_j]
\end{array}\right\}
\end{displaymath}

Figure \ref{fig:steady-state} (b) depicts a sample {\splitjoin}. The
following are the steady states of the {\splitjoin}'s children: $$
\begin{array}{lrlr} S_A = & \left\{[1], \{A\}, { \left[
\begin{array}{c} 2 \\ 2 \\ 1
\end{array}
\right]}, [] \right\}, & S_B = & \left\{[1], \{B\}, { \left[
\begin{array}{c} 3 \\ 2 \\ 6
\end{array}
\right]}, [] \right\}
\end{array}
$$ For this {\splitjoin}, we select $k = 0$ (we use the left-most child
to compute $a_j'$).  We get the following $v'$, $a_s'$ and $a_j'$

\begin{displaymath}
\begin{array}{rl}
v' = & \left[
\begin{array}{c}
2 * 2 (2)\\
1 * 2 (2)
\end{array}
\right] = \left[
\begin{array}{c}
8 \\ 4
\end{array}
\right] \\
a_s' = & 1 * 2 (2 * 2) = 8 \\
a_j' = & 2 * 1 (2 * 2) = 8
\end{array}
\end{displaymath}

Thus $\gcd(u', a_s', a_j') = \gcd(8,4,8,8) = 4$.  Now we obtain

\begin{displaymath}
\begin{array}{rl}
v = & {v \over 4} = {1 \over 4} \left[
\begin{array}{c}
8 \\ 4
\end{array}
\right] =  \left[
\begin{array}{c}
2 \\ 1
\end{array}
\right]\\
a_s = & {a_s' \over 4} = {8 \over 4} = 2 \\
a_j' = & {a_j' \over 4} = {8 \over 4} = 2
\end{array}
\end{displaymath}

Finally, we construct $S_{sj}$:

\begin{displaymath}
S_{sj} = \left\{
\begin{array}{c}
2 * S_{sj_0, m} \circ 1 * S_{sj_1, m} \circ [2\ 2], \\
S_{sj_0, N} \circ S_{sj_1, N} \circ \{sj_s, sj_j\}, \\
\left[
\begin{array}{c}
2 * 3 \\ 2 * 3 \\ 2 * 4
\end{array}
\right], \left[
\begin{array}{c}
2 \\ 1 \\ 2 \\ 2
\end{array}\right]
\end{array} \right\}
\end{displaymath}

\begin{figure}\begin{center}
\begin{minipage}{2in}
\centering \psfig{figure=splitjoin-illegal.eps,width=2in}
\end{minipage}
\end{center}
\caption{An illegal {\splitjoin}} \label{fig:splitjoin-illegal}
\end{figure}

It is important to note, that it is not always possible to compute
a unique $v''$ for all possible {\splitjoins}. The reason is that
unbalanced production/consumption ratios between different
children of a {\splitjoin} can cause data to buffer up infinitely.

\begin{definition}[Valid {\splitjoin}] A {\splitjoin} is valid
{\emph iff} $\forall k, 0 \le k < n-1, a_{j,k}'' = a''_{j,k+1}$,
using notation of $a_{j,k}''$ to indicate that $k$th child of the
{\splitjoin} was used to compute the value of $a_j''$.
\end{definition}

An example of an illegal {\splitjoin} is depicted in Figure
\ref{fig:splitjoin-illegal}.  The rates of throughput of data for
the left child mean that for every execution of the {\splitter}, the
{\joiner} needs to be executed exactly once to drain all data
entering the {\splitjoin}.  The rates of throughput of data for the
right child mean that for every execution of the {\splitter}, the
{\joiner} needs to be executed exactly twice to drain all data
entering the {\splitjoin}. That means that consumption of data by
the {\joiner} will be relatively slower on the right side, causing
data to buffer up. This means that the given {\splitjoin} does not
have a steady state.

If a {\splitjoin} is such that it does not have a steady state, it
is considered an illegal {\splitjoin}.  It cannot be executed
repeatedly without infinite buffering, so a practical target for
{\StreamIt} cannot execute it.  The calculations presented here
assume that the {\splitjoin} is legal.  In order to check if a given
{\splitjoin} is legal, we test if selecting a different child for
calculation of $a_j''$ yields a different $a_j''$. If it does,
then the two paths tested have different production/consumption
rates, and the {\splitjoin} does not have a steady state.

\subsubsubsection{\feedbackloop}

Let {\feedbackloop} $fl$ have children $B$ (the body child) and $L$
(the feedback loop child). Let the {\joiner} and the {\splitter} of
the {\feedbackloop} be denoted $fl_j$ and $fl_s$. Let $w_{j,I}$ and
$w_{j,L}$ denote the number of data items consumed by the {\joiner}
from the {\Input} {{\Channel}} to the {\feedbackloop} and from $fl_L$,
respectively.  Let $w_{s,O}$ and $w_{s,F}$ denote the number of
data items pushed by the {\splitter} onto the {\feedbackloop}'s {\Input}
{{\Channel}} and to $fl_L$ respectively.  We are computing $S_{fl}$.

First we calculate $S_{B}$ and $S_{L}$.

Now we compute a fractional vector $v'' = [a_B''\ a_L''\ a_s''\
a_j'']$ such that executing the body child $a_B''$ times, the
{\splitter} $a_s''$ times, the loop child $a_F''$ times and the
{\joiner} $a_j''$ times will not change the amount of data buffered
up in the {\feedbackloop}.  Thus

\begin{displaymath}
\begin{array}{rcl}
a_B' * u_B & = & a_s' * o_s \\
a_L' * u_B & = & a_j' * w_{j, L} \\
a_s' * w_{s, F} & = & a_L' * o_B \\
a_j' * u_j & = & a_B' * o_B \\
\end{array}
\end{displaymath}

We begin with setting $a_j'' = 1$. $B$ needs to be executed $a_B''
= u_j \over o_B$ times, the {\splitter} needs to be executed $a_s''
= {u_j \over o_B}{u_B \over o_s}$ times and $L$ needs to be
executed $a_L'' = {u_j \over o_B}{u_B \over o_s}{w_{s,L} \over
o_L}$ times. Furthermore, in order to assure that the
{\feedbackloop} has a valid steady state, we continue going around
the loop, the {\joiner} must require ${u_j \over o_B}{u_B \over
o_s}{w_{s,L} \over o_L}{u_L \over w_{j,L}} = 1$.  If this
condition is not satisfied, the {\feedbackloop} does not have a
steady state. This is a necessary, but not a sufficient condition
for a {\feedbackloop} to be valid.

Next we compute an integer vector $v' = [a_B'\ a_L'\ a_s'\ a_j']$
such that executing B $a_B'$ times, {\splitter} $a_s'$ times, L
$a_L'$ times and {\joiner} $a_j'$ times will not change the amount
of data buffered in the {\splitjoin}. We do this by multiplying
$v''$ by $o_B * o_s * o_L$.

\begin{displaymath}
\begin{array}{rl}
a_B' = & u_j * o_s * o_L \\
a_L' = & u_j * u_B * w_{s,L} \\
a_j = & o_B * o_s * o_L \\
a_s = & u_j * u_B * o_L
\end{array}
\end{displaymath}

We now use $v'$ to compute $v = [a_B\ a_L\ a_s\ a_j]$, a minimal
steady state for the {\feedbackloop}.  We do this by finding an
integer $g$, the $\gcd$ of all elements in $v'$ and computing $v =
{v' \over g}$.

Finally, we construct $S_{fj}$ as follows:

\begin{displaymath}
S_{fj} = \left\{
\begin{array}{c}
a_B * S_{B,m} \circ a_L * S_{L,m} \circ [a_s \ a_j], \\
S_{B,N} \circ S_{L,N} \circ \{fl_s, fl_j\}, \\
\left[\begin{array}{c}
a_j * w_{j,I} \\
a_j * w_{j,I} \\
a_s * w_{s,O}
\end{array} \right], v
\end{array} \right\}
\end{displaymath}

Figure \ref{fig:steady-state}(c) depicts a sample {\feedbackloop}.
The following are the steady states of the {\splitjoin}'s children:
$$
\begin{array}{lrlr} S_B = & \left\{[1], \{B\}, { \left[
\begin{array}{c} 2 \\ 2 \\ 1
\end{array}
\right]}, [] \right\}, & S_L = & \left\{[1], \{L\}, { \left[
\begin{array}{c} 5 \\ 5 \\ 6
\end{array}
\right]}, [] \right\}
\end{array}
$$ We compute $v'$ for this {\feedbackloop}:

\begin{displaymath}
v' = \left[
\begin{array}{c}
5 * 3 * 5 \\
5 * 1 * 3 \\
5 * 1 * 5 \\
2 * 3 * 5
\end{array}\right] = \left[
\begin{array}{c}
75 \\
15 \\
25 \\
30
\end{array}\right]
\end{displaymath}

Thus $g = \gcd(75,15,25,30) = 5$ and

\begin{displaymath}
v = {1 \over 5} \left[
\begin{array}{c}
15 \\
3 \\
5 \\
6
\end{array}\right]
\end{displaymath}

Finally, we construct $S_{fl}$

\begin{displaymath}
S_{fl} = \left\{
\begin{array}{c}
15 * S_{B, m} \circ 3 * S_{L, m} \circ [5\ 6], \\
S_{B, N} \circ S_{L, N} \circ \{fl_s, fl_j\}, \\
\left[
\begin{array}{c}
6 * 2 \\ 6 * 2 \\ 5 * 3
\end{array}
\right], \left[
\begin{array}{c}
15 \\ 3 \\ 5 \\ 6
\end{array}\right]
\end{array} \right\}
\end{displaymath}

\subsection{Initialization for Peeking}
\label{sec:init-peeking}

Consider a {\filter} $f$, with peek amount of 2 and a pop amount of
1.  When a {\StreamIt} program is first run, there is no data
present on any of the {{\Channels}}.  This means that for the first
execution, filter $f$ requires that two data items be pushed onto
its {\Input} {{\Channel}}.  After the first execution of $f$, it will
have consumed one data item, and left at least one data item on
its {\Input} {{\Channel}}.  Thus in order to execute $f$ for the second
time, at most one extra data item needs to be pushed onto $f$'s
{\Input} {{\Channel}}.  The same situation persists for all subsequent
executions of $f$ - at most one additional data item is required
on $f$'s {\Input} {{\Channel}} in order to execute $f$.

This example illustrates that first execution of a {\filter} may
require special treatment.  Namely, the source for {\filter}'s data
may need to push more data onto {\filter}'s {\Input} {{\Channel}} for
{\filter}'s first execution.  Due to this condition, a {\StreamIt}
program may need to be initialized before it can enter steady
state execution.

There are other constraints (latency constraints) which may
require more complex initialization.  These will be discussed in
Chapter \ref{chpt:constrained}.

After an execution, a {\filter} $f$ must leave at least $e_f - o_f$
data on its {\Input} {{\Channel}}.  Thus, if the only constraints on
initialization are peek-related, it is a sufficient condition for
entering steady state schedule that $\forall f \in {\filters}, in_f
\ge e_f - o_f$.

Specific strategies for generating initialization schedules for
peeking will be presented in Chapter \ref{chpt:hierarchical} and
Chapter \ref{chpt:phased}.

\subsection{Schedules}
\label{sec:general:schedules}

 Once a program has been
initialized, it is ready to execute its steady state. In order to
do this, a steady state schedule needs to be computed. The steady
states computed above do not indicate the ordering of execution of
the nodes, only how many times the nodes need to be executed.

A schedule is an ordering of nodes in a {\StreamIt} streams. In
order to execute the schedule, we iterate through all of its nodes
in order of appearance and execute them one by one.  For example
in order to execute schedule $\{ABBCCBBBCC\}$ we would execute
node A once, then node B, node B again, C two times, B three times
and C twice again, in that order.

In order to shorten the above schedule we can run-length encode
it.  The schedule becomes $\{A \{2B\}\{2C\}\{3B\}\{3C\}\}$.

\subsection{Schedule Size vs. Buffer Size}
\label{sec:sched-vs-buffer}

\begin{figure}
\begin{center}

\psfig{figure=pipeline-buffers.eps,width=0.6in} \caption[4 {\filter}
{\pipeline}]{Sample 4 {\filter} {\pipeline}.  This {\pipeline} is
the same as one in Figure \ref{fig:steady-state} (a), except that
its children do not peek extra data} \label{fig:pipeline-buffers}
\end{center}
\end{figure}

When creating a schedule, two very important properties of it are
schedule size and amount of buffering required.  Schedule size
depends on encoding the schedule in an efficient way, while amount
of space required depends only on order of execution of nodes. The
two are related, however, because order of execution of {\filters}
affects how efficiently the schedule can be encoded.

For example, execution of {\filters} in {\pipeline} depicted in Figure
\ref{fig:pipeline-buffers} can be ordered in two simple ways, one
resulting in a large schedule but minimal amount of buffering, the
other resulting in a small schedule but a large amount of
buffering.

The steady schedule of the {\pipeline} in Figure
\ref{fig:pipeline-buffers} executes {\filter} $A$ 4 times, {\filter}
$B$ 6 times, {\filter} $C$ 9 times and {\filter} $D$ 3 times. Writing
out a schedule that requires minimal buffering results in schedule
$\{AB\{2C\}BCDAB\{2C\}ABCDB\{2C\}ABCD\}$.  This schedule requires
a buffer for 4 data items between {\filters} $A$ and $B$, 4 items
between $B$ and $C$ and 3 items between $C$ and $D$, resulting in
total buffers size 11, assuming data items in all buffers require
the same amount of space. The schedule itself has 18 entries.

To compare, writing the schedule in the most compact method we get
$$\{4A\}\{6B\}\{9C\}\{3D\}$$  This schedule requires a buffer for
12 data items between {\filters} $A$ and $B$, 18 items between $B$
and $C$, and 9 data items between $C$ and $D$, resulting in total
buffers size 39.  The schedule has 4 entries.

We can compare the storage efficiency of these two schedules by
assuming that one data item in a buffer requires $x$ amount of
memory and each entry in a schedule requires $y$ amount of memory.
Thus the two schedules will require the same amount of storage to
store themselves and execute if $11 x + 18 y = 39 x + 4 y$.

\begin{displaymath}
\begin{array}{rcl}
11 x + 18 y & = & 39 x + 4 y \\
14 y & = & 28 x \\
y & = & 2x
\end{array}
\end{displaymath}

Thus the smaller schedule is more efficient if every data item
requires less than twice the amount of storage than every entry in
the schedule.

One of the difficulties in scheduling {\StreamIt} programs lies in
finding a good set of trade-offs between schedule size and
buffering requirements.

\begin{comment}

\subsection{Minimum Buffer Size between {\filters}}

As illustrated above, the amount of buffering in a {\pipeline} can
be affected greatly by the order of executions of {\filters} in the
{\pipeline}.  The following equation calculates the minimal buffer
size required in order for two {\filters} to be able to push data
between each other indefinitely in the most buffer-efficient way.
Buffers this size cannot always be achieved, because some
components require that data be buffered up for execution (ex.
{\feedbackloops} require data to exist internally in order to
execution to advance) or because extra latency constrains require
additional buffering.

\begin{equation}
buffer_{A \to B} = \left\lceil {{peek_B} \over {\gcd(push_A,
pop_B)}} - 1 \right\rceil \gcd (push_A, pop_B) + push_A
\end{equation}

\emph{I can explain this equation, but I cannot prove it.  what
should I do with this?  it's not necessary for the thesis, but it
is a neat result we never published (PLDI submission), nor have I
seen it in any other papers (nobody does peeking, so it can't be
anywhere else)}

\end{comment}

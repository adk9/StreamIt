\section{Streaming Virtual Machine API}

The Streaming Virtual Machine API consists of a set of streaming
computation kernels that are connected in a stream graph.
General-purpose threaded code controls graph construction and
execution.  We describe the API for stream kernels in
Section~\ref{sec:kernel} and the API for stream control in
Section~\ref{sec:processor}.

\subsection{Stream Kernel API}
\label{sec:kernel}

\subsubsection{Overview}

Each kernel is represented as a C++ object, with the following
components:

\begin{enumerate}

\item A constructor, which receives the following:

\begin{itemize}
\item The architecture resource where the kernel will execute.
\item A block of memory for spilling local variables.
\item The inputs and outputs for the kernel.
\item Any other kernel-specific initialization data.
\end{itemize}

\item A {\it work} function that represents the steady-state execution
step.

\item A {\it workInfo} function that describes the properties of {\tt
work} to the low-level compiler.

\item (Optional) A {\it prework} function that is called before the
first execution of {\it work}, as well as an associated {\it
preworkInfo} function.

\item (Optional) A {\it postwork} function that is called after the
last execution of {\it work}, as well as an associated {\it
postworkInfo} function.

\item (Optional) Data members, which represent local kernel data that
are preserved between invocations of {\it work}.

\end{enumerate}

\noindent For example, a kernel for a simple amplifier could be as follows:
{\small
\begin{verbatim}
  class AmplifierKernel : public Kernel {
    IStream<float> in;
    OStream<float> out;
    int N;

  public:
    AmplifierKernel(int _N, VM_NODE location, IOBlock<byte> scratch, 
                    IStream<float> _in, OStream<float> _out) : 
                    public Kernel (location, scratch, _in, _out) {
      in = _in;
      out = _out;
      N = _N;
    }

  protected:
    STATUS work() {
      if (canPop(1) && canPush(1)) {
        out.push(in.pop() * N);
        return RUNNING;
      } else {
        return FINISHED;
      }
    }

    void workInfo() {
      KernelInfo.setPop(in, 1);
      KernelInfo.setPush(out, 1);
      KernelInfo.isSIMD();
    }
  }  
\end{verbatim}}
As evident in the example, input and output streams are represented by
objects that support {\tt push} and {\tt pop} operations.  In the
following sections, we describe the API for streams
(Section~\ref{sec:kerstreams}), the API for blocks
(Section~\ref{sec:blocks}), and the API for kernels
(Section~\ref{sec:kernels}).

\begin{figure}[t]
\begin{center}
\psfig{figure=inherit.eps,width=6in}
\end{center}
\vspace{-12pt}
\caption{Class hierarchy diagram for streams and blocks.\protect\label{fig:inherit}}
\end{figure}

\input{declgrid}

\subsubsection{Streams}
\label{sec:kerstreams}

A {\it stream} is a C++ data type that represents a sequence of items
of a given type.  The kernel API supports several kinds of streams,
which vary in two respects: 
\begin{enumerate}

\item Whether the stream is used for input, output, or both.

\item Whether the elements of the stream are ordered or unordered.
Ordered streams have the semantics of a FIFO queue, whereas unordered
streams are useful when a pool of data needs to be processed in any
order, {\it e.g.}, for network packets.

\end{enumerate}
All combinations of these attributes represent a valid kind of stream,
and thus there are six stream types (see Figure~\ref{fig:declgrid}).
For the sake of clarifying the specification and the implementation of
the runtime system, this proposal uses inheritance to describe these
types\footnote{However, nothing in the specification relies on the
inheritance relationships for correctness, so these could be expanded
into six stand-alone types if desired.}(see Figure~\ref{fig:inherit}).

Each stream is based on a template type {\tt T} to allow type-safe
access to its data elements.  This type must have a fixed size.
Variable sized stream records can be supported at the language-level
and compiled into the fixed size scheme using a data encoding.

The rest of this section gives details for each of the functions
supported by a stream.  It refers to the {\tt StreamBuffer} class,
which is described in Section~\ref{sec:procstreams} as a structure
that is allocated in the stream control code in order to store the
items that appear in streams.  The pseudocode below gives a reference
implementation of each stream method, assuming that each {\tt
StreamBuffer} {\it s} is implemented as a circular buffer with an
array {\it data} of length {\it capacity}, a {\it start} pointer, and
an {\it end} pointer.

\ssss{constructor} Each stream provides a constructor with a single
argument of type {\tt StreamBuffer}.  The constructor saves this {\tt
StreamBuffer} in a field {\tt s} for other functions to use as the
interface to the storage space for the stream.

\ssss{push} For output streams, the {\tt push} method enqueues a value
onto the end of the stream.  If the stream cannot hold any more items
({\it i.e.}, if {\tt canPush(1)} is {\tt false}), then its behavior is
undefined.

{\small
\begin{verbatim}
  template <class T>
  void OStreamUnordered<T> :: push(T& val) {
    if (s->getLength() == s->capacity) {
      waitForDrain();
    }
    if (s->end == s->capacity) {
      s->end = 0;
    }
    s->data[s->end++] = val;
    // keep count of items pushed for use by StreamBuffer.getTotalLength()
    s->totalLength++;
  }
\end{verbatim}}

\ssss{pop} For input streams, the {\tt pop} method dequeues a value
from the front of the stream.  If the stream has ended ({\it i.e.}, if
{\tt canPop(1)} is {\tt false}), then its behavior is undefined.

{\small
\begin{verbatim}
  template <class T>
  T IStreamUnordered<T> :: pop() {
    if (s->getLength() < 1) {
      waitForFill();
    }
    if (s->start == s->capacity) {
      start = 0;
    }
    T result = s->data[s->start++];
    return result;
  }
\end{verbatim}}

\ssss{canPush} For output streams, the {\tt canPush} method returns
whether or not it will be possible to push $n$ additional items onto
the stream.  Note that for this could return {\tt true} even if there
are currently less than $n$ free spaces in the buffer, since further
execution of the stream graph could consume some items.  The function
must take this into account, and only return {\tt false} if it will
never be possible to push $n$ items at any point in the future.

Note that {\tt canPush} is allowed to cause a change in the number of
free spaces in the stream.  In the reference implementation, we drain
the stream graph as much as possible in the event that fewer than $n$
items are currently available.

{\small
\begin{verbatim}
  template <class T>
  boolean OStreamUnordered<T> :: canPush(int n) {
    if (s->capacity - s->getLength() >= n) {
      return true;
    } else {
      if (graphCanDrain()) {
        waitForDrain();
        return (s->capacity - s->getLength() >= n);
      } else {
        return false;
      }
    }
  }
\end{verbatim}}

\ssss{canPop} For input streams, the {\tt canPop} method returns
whether or not it will be possible to pop $n$ additional items from
the stream.  Just as with {\tt canPush} above, {\tt canPop} returns
false only if it will never be possible to pop an item from the buffer
at some point in the future.

{\small
\begin{verbatim}
  template <class T>
  boolean IStreamUnordered<T> :: canPop(int n) {
    if (s->getLength() >= n) {
      return true;
    } else {
      if (graphCanFill()) {
        waitForFill();
        return (s->getLength() >= n);
      } else {
        return false;
      }
    }
  }
\end{verbatim}}

\ssss{peek} For ordered input streams, the {\tt peek} method returns
the element at position {\it index}, where {\it index} is zero-indexed
(such that {\tt peek(0)} gives the same value as {\tt pop()}).  If
there are fewer than $\mt{index}+1$ items in the stream ({\it i.e.},
if {\tt canPop(index+1)} is {\tt false}), or if $\mt{index}+1$ exceeds
the capacity of the buffer, then the return value is undefined.

{\small
\begin{verbatim}
  template <class T>
  T IStream<T> :: peek(int index) {
    if (s->getLength() < index+1) {
      waitForFill();
    }
    int i = s->start+index;
    if (i >= s->capacity) {
      i -= s->capacity;
    }
    return s->data[i];
  }
\end{verbatim}}


%% \begin{figure}[t]
%% \begin{tabular}{c|c|c|c}
%% ~ & Input & Output & Input and Output
%% \\ \hline
%% \lefttab{Block}
%% &
%% \begin{minipage}{1.9in}
%%   \scriptsize
%%   \begin{verbatim}

%% template <class T>
%% class IBlock {
%%   IBlock(StreamBuffer<T> &s);
%%   T read(int index);
%% }


%%   \end{verbatim}
%% \end{minipage}
%% &
%% \begin{minipage}{1.6in}
%%   \scriptsize
%%   \begin{verbatim}

%% template <class T>
%% class OBlock {
%% public:
%%   OBlock(StreamBuffer<T> &s);
%%   void write(int index, T &val);
%% }

%%   \end{verbatim}
%% \end{minipage}
%% &
%% \begin{minipage}{1.8in}
%%   \scriptsize
%%   \begin{verbatim}

%% template <class T>
%% class IOBlock : 
%%        IBlock<T>, 
%%        OBlock<T> {
%% public:
%%   IOBlock(StreamBuffer<T> &s);
%% }
%%   \end{verbatim}
%% \end{minipage}
%% \end{tabular}
%% \caption{Class declarations for blocks.\protect\label{fig:declgrid}}
%% \end{figure}

\subsubsection{Blocks}
\label{sec:blocks}

Streams are intended for sequential production and consumption of data
items.  For kernels that require random access to a fixed set of
elements, the API provides the {\it block} abstraction.  A block is
simply a contiguous region of memory; it is constructed with a
capacity, a memory node, and an address.  Since some kernels use a
given block only for input or only for output, we divide the block
classes into {\tt IBlock} and {\tt OBlock}, with {\tt IOBlock}
extending both (see Figure~\ref{fig:inherit}).

The {\tt OBlock} class implements the {\tt write} and {\tt
getCapacity} functions:

{\small
\begin{verbatim}
  template<class T>
  class OBlock {
  public:
    // construct block of size <capacity>, at <address> of <memLocation>
    OBlock(int capacity, VM_NODE_TYPE_MEM memLocation, int address);

    // construct block of size <capacity>, in registers of <procLocation>
    OBlock(int capacity, VM_NODE_TYPE_PROC procLocation);

    // write <val> to <index> of this.  Requires that index < capacity.
    void write(int index, T& val);

    // return capacity of this
    int getCapacity();
  }
\end{verbatim}}

\noindent The {\tt IBlock} class implements the {\tt read} and {\tt
getCapacity} functions:

{\small
\begin{verbatim}
  template<class T>
  class IBlock {
  public:
    // construct block of size <capacity>, at <address> of <memLocation>
    IBlock(int capacity, VM_NODE_TYPE_MEM memLocation, int address);

    // construct block of size <capacity>, in registers of <procLocation>
    IBlock(int capacity, VM_NODE_TYPE_PROC procLocation);

    // read element <index> from this.  Requires that index < capacity.
    T read(int index);

    // return capacity of this
    int getCapacity();
  }
\end{verbatim}}

\noindent The {\tt IOBlock} class extends both {\tt IBlock} and {\tt OBlock}:

{\small
\begin{verbatim}
  template<class T>
  class IOBlock : public IBlock, public OBlock {
  public:
    // construct block of size <capacity>, at <address> of <memLocation>
    IOBlock(int capacity, VM_NODE_TYPE_MEM memLocation, int address);

    // construct block of size <capacity>, in registers of <procLocation>
    IOBlock(int capacity, VM_NODE_TYPE_PROC procLocation);
}
\end{verbatim}}

\subsubsection{Kernels}
\label{sec:kernels}

Each kernel is described as a subclass of the basic kernel class:
{\small
\begin{verbatim}
  class Kernel {
    // status codes
    enum STATUS {
      UNSTARTED,
      RUNNING,
      SUSPENDED,
      FINISHED
    }
  protected:
    // construct a kernel on <location> that uses <scratch> to spill local variables,
    // and is connected to streams or blocks <sb1>, <sb2>, ... .  Also, set private 
    // <status> to UNSTARTED.
    Kernel(VM_NODE location, IOBlock<byte> scratch, BaseMemory sb1, BaseMemory sb2=0, ... );

    // steady-state execution step.  Returns the new status of the kernel.
    virtual STATUS work();

    // (optional) Called before first invocation of work.  Returns status of kernel.
    virtual STATUS prework();

    // (optional) Called after last invocation of work.
    virtual void postwork();

    // annotations for work, prework, and postwork functions
    virtual void workInfo();
    virtual void preworkInfo();
    virtual void postworkInfo();

  private:
    // non-blocking method that starts or resumes execution of this kernel.  The kernel 
    // continues to run until its status is SUSPENDED or FINISHED.  This method is only
    // called from Graph.run.
    void run();
   
  public:
    // non-blocking method that indicates that the kernel should not enter the RUNNING state
    // again until kernels <predececessor1>, <predecessor2>, ... are all FINISHED.
    void waitFor(Kernel& predecessor1 = 0, Kernel& predecessor2 = 0, ...);

    // blocking method that waits until the kernel's status is something other than RUNNING,
    // at which point it returns the status.
    STATUS wait();

    // non-blocking method that returns the current status of the kernel
    STATUS getStatus();

    // non-blocking method that interrupts execution of a kernel on a best-effort basis 
    // to ensure that the kernel's status is FINISHED.  This should be followed by a call to 
    // wait() if the control thread wants to ensure that the kernel is finished.
    void terminate();

  private:
    // status of kernel
    STATUS status;
    // Graph is a friend in order for it to call run
    friend class Graph;
  }  
\end{verbatim}}
The constructor of {\tt Kernel} receives two special arguments that
are signals to the low-level compiler.  The first is the {\tt
location}, which indicates which processor resource should be used to
execute the kernel.  The second is a {\tt scratch} space, which is a
block of memory in which the low-level compiler can store local
variables if they overflow the registers of the kernel processor.  The
scratch space is always of type {\tt IOBlock<byte>}.  

Also, in any subclass of {\tt Kernel}, the input and output streams
are received in the constructor and must be directly stored as fields
(with a one-to-one mapping from fields to streams, and no surrounding
control flow).  This allows {\tt prework}, {\tt work}, and {\tt
postwork} to access the streams.

Within a kernel, standard {\tt public}, {\tt protected}, and {\tt
private} modifiers are used to indicate what is visible outside the
class--in particular, to the stream control code.  As described in
Section~\ref{sec:streamgraph}, the stream control code can read and
write the public fields of a kernel when it is not in the {\tt
RUNNING} state.  However, the kernel cannot declare any public
methods; rather, all computations on public data should be done in the
control code itself.

\sss{Runtime Model}

\begin{figure}[t]
\begin{center}
\psfig{figure=kernel-status.eps,width=3.5in}
\end{center}
\vspace{-12pt}
\caption{Legal transitions of a kernel's {\tt status} before and after
a call to {\tt run}.\protect\label{fig:kernel-status}}
\end{figure}

The {\tt run} function is the external interface for executing a
kernel.  It operates as follows: 
{\small
\begin{verbatim}
  void Kernel::run(Kernel& predecessor1 = 0, Kernel& predecessor2 = 0, ...) {
    // wait for predecessor kernels to finish
    for (all kernels k specified in previous calls to waitFor) {
      k.wait();
    }

    if (status == UNSTARTED) {
      status = prework();
    } else if (status == SUSPENDED) {
      status = RUNNING;
    }
    while (status == RUNNING) {
      status = work();
    }
    if (status == FINISHED) {
      postWork();
    }
  } 
\end{verbatim}}
That is, the {\tt run} function calls the component work functions in
the order specified until one of them returns a status of {\tt
SUSPENDED} or {\tt FINISHED}.  If the status is {\tt SUSPENDED}, then
the {\tt run} function might be called again from the control code.
For example, if the control code is monitoring some aspect of the
kernel, then the kernel should suspend itself after executing for a
certain number of iterations so that the control code can inspect its
public fields.  Alternatively, the kernel itself could do the
monitoring and suspend itself only when a particular condition is
satisfied.  A transition diagram for the legal states of a kernel
appears in Figure~\ref{fig:kernel-status}.

Note that no kernel can override the {\tt run} function.  The behavior
of {\tt run} is exactly specified by the above code.

\sss{Annotations}

There are several pieces of information that are available to the
high-level compiler which should be transferred to the low-level
compiler in the form of annotations.  Each annotation takes the form
of a function call to the {\tt KernelInfo} class.  Calls from the {\tt
workInfo} function apply to {\tt work}, calls from {\tt preworkInfo}
apply to {\tt prework}, and calls from {\tt postworkInfo} apply to
{\tt postWork}.
{\small
\begin{verbatim}
  class KernelInfo {
  public:
    // these functions declare the push, pop, and peek rate of a
    // work or prework function with respect to a given stream.
    static void setPush(BaseStream str, int push);
    static void setPop(BaseStream str, int pop);
    static void setPeek(BaseStream str, int peek);

    // these functions indicate a dynamic rate that is unknown at
    // compile time.  However, they can optionally provide the 
    // maximum rate and an estimate of the average rate to help
    // the low-level compiler.
    static void setDynamicPush(BaseStream str, int max=ALL, float estimate=UNKNOWN);
    static void setDynamicPop(BaseStream str, int max=ALL, float estimate=UNKNOWN);
    static void setDynamicPeek(BaseStream str, int max=ALL, float estimate=UNKNOWN);

    // indicates that a work or prework function is data-parallel 
    // and fit for SIMD execution
    static void isSIMD();
  }  
\end{verbatim}}

All arguments to annotations must be compile-time constants.  For
example, in a kernel from a MergeSort, the input rates are marked
dynamic (with an estimate of 0.5 items per stream on average) because
they depend on values from the input streams:
{\small
\begin{verbatim}
  class MergeKernel : public Kernel {
    IStream<int> in1;
    IStream<int> in2;
    OStream<int> out;
  public:
    MergeKernel(VM_NODE location, IOBlock<byte> scratch,
                IStream<int> _in1, IStream<int> _in2, OStream<int> _out) :
                Kernel (location, scratch, _in1, _in2, _out) {
      in1 = _in1;
      in2 = _in2;
      out = _out;
    }

  protected:
    STATUS work() {
      // we're done if both input streams have ended, or if there will never be space for output
      if ((!in1.canPop(1) && !in2.canPop(1)) || !out.canPush(1)) {
        return FINISHED;
      }

      // if in1 is empty, draw from in2
      if (!in1.canPop(1)) {          
        out.push(in2.pop());
        return false;
      }

      // if in2 is empty, draw from in1
      if (!in2.canPop(1)) {
        out.push(in1.pop());
        return false;
      } 

      // otherwise, compare elements from in1 and in2
      if (in1.peek(0) < in2.peek(0)) {
        out.push(in1.pop());
      } else {
        out.push(in2.pop());
      }

      return RUNNING;
    }

    void workInfo() {
      KernelInfo.setDynamicPush(in1, 0.5);
      KernelInfo.setDynamicPop(in2, 0.5);
      KernelInfo.setPush(out, 1);
    }
  }  
\end{verbatim}}

All instances of {\tt IStream} and {\tt IStreamUnordered} must be
annotated with their pop and peek rates, and all instances of {\tt
OStream} and {\tt OStreamUnordered} must be annotated with their push
rates.

\sss{Kernel Restrictions}

Only a subset of C++ is supported from within a kernel; restrictions
are listed in Figure~\ref{fig:restrict}.  

\begin{figure}[t]
\framebox[6.5in]{
\begin{minipage}{6in}

\begin{enumerate}

\item No pointers.

\item No dynamic memory allocation.

\item No accesses to global memory.

\item No GOTO statements (all control flow is structured).

\item No recursive functions (all function calls have inline
semantics).

\item No calls to functions that violate any of these restrictions.

\item No references to templates or objects besides the classes
described in this document.  Further, no creation or casting of
objects within kernels.

\item All kernel functions (including the constructor) must receive their arguments by value
(not by reference.)  Also, the kernel constructor cannot invoke any member functions of a
stream object.

\item Supported opcodes are only the logical, arithmetic, and boolean
operations found in C (no special-purpose DSP operations).

\item Supported types include 64-bit signed and unsigned {\tt long},
32-bit {\tt float}, 32-bit signed and unsigned {\tt int}, 16-bit
signed and unsigned {\tt short}, 8-bit {\tt byte}, {\tt boolean},
arrays with a fixed (int literal) length, and {\tt struct}'s
containing members of any other type.

\end{enumerate}

\caption{Restrictions on C++ code within kernels.\protect\label{fig:restrict}}
\end{minipage}}
\end{figure}

\subsection{Stream Control API}
\label{sec:processor}

\subsubsection{Overview}
\label{sec:streamover}

A control thread in a restricted subset of C++ is used to manage
stream memory and to supervise the execution of stream kernels.  All
static stream operations are represented by explicit stream graphs, in
which kernel objects are the nodes and stream buffers are the edges.
The network model is also integrated into the graph representation:
each stream buffer is annotated with the memory bank in which it
resides, and pre-defined network kernels are used to communicate
between streams in different memories.  Dynamic operations and dynamic
control flow are fully supported in the code that constructs stream
graphs and transitions between them.

An example of the stream control API is as follows:
{\small
\begin{verbatim}
  // read file into memory location of s0 (not part of SVM API)
  int length1 = readFile("input.dat", 1024, MEM1, 0x1000);

  // declare streams with their size and the location in which they are held
  StreamBuffer<float> s0(length1, MEM1, 0x1000, length1), 
                      s1(128, SRF1, 0x200), 
                      s2(1024, SRF1, 0x280);
  IOBlock<byte> scratch2(32, SRF1, 0x680);

  // set up a graph to do some audio filtering and compression
  Kernel copy = new Copy<float>(s0, s1, PROC1);
  Kernel rle  = new RunLengthEncode(PROC1, scratch2, s1, s2);
  Graph compress1(copy, rle);

  // run the kernels
  compress1.run();
  compress1.wait();

  // if the output is still too large, run additional compression, 
  // overwriting s2 in place
  int length2 = s2.getTotalLength();
  if (length2 > SIZE_THRESHOLD) {
    StreamBuffer<float> s3(1024, SRF1, 0x280);
    IOBlock<byte> scratch3(32, SRF1, 0x680);
    
    Kernel zip = new ZipCompress(PROC2, scratch3, s2, s3)
    Graph compress2(zip);
    compress2.run();
    compress2.wait();
    length2 = s3.getTotalLength();
  }

  // store the result from memory to "output.dat" (not part of SVM API)
  writeFile("output.dat", length2, MEM1, 0x280);
\end{verbatim}}

The above code fragment illustrates several aspects of the stream
control API.  In the following, Section~\ref{sec:procstreams}
describes the {\tt StreamBuffer} class; Section~\ref{sec:streamgraph}
explains the construction and execution of stream graphs;
Section~\ref{sec:predef} describes a pre-defined set of kernels for
dealing with memory and network operations (such as the {\tt Copy}
kernel above); and Section~\ref{sec:library} describes support for
architecture specific black-box kernels.

\subsubsection{Stream Buffers}
\label{sec:procstreams}

The control API uses the {\tt StreamBuffer} class to allocate storage
space for the contents of a stream:
{\small
\begin{verbatim}
  template<class T>
  class StreamBuffer {
  public:
    // make a stream buffer that can hold at most <capacity> elements,
    // allocated at <address> of memory node <memLocation>, with <initLength>
    // items already in place.  The last two arguments are optional hints to
    // the low-level compiler:  <aliased> is true if some other stream buffer can
    // overlap this in memory, and <startAtZero> is true if the first element of
    // this is always stored at <address> instead of being offset.
    StreamBuffer(int capacity, VM_NODE_TYPE_MEM memLocation, int address, 
                 int initLength=0, boolean aliased=true, boolean startAtZero=true);

    // same as above, for stream held in registers of a processor
    StreamBuffer(int capacity, VM_NODE_TYPE_PROC procLocation, int initLength=0);

    // returns capacity of the buffer
    int getCapacity();

    // returns number of live items the buffer
    int getLength();

    // returns total number of items that were pushed onto this since
    // construction or last reset
    int getTotalLength();

    // clears the elements of the buffer, as well as totalLength
    void reset();

    // default copy operation
    StreamBuffer(StreamBuffer& _s);

    // private data and friends included only for benefit of reference implementation (see text)
  private:
    T* data;
    int capacity;
    int start;
    int end;
    int totalLength;
    friend IStream; friend IStreamUnordered;
    friend OStream; friend OStreamUnordered;
    friend IOStream; friend IOStreamUnordered;
  }
\end{verbatim}}

A {\tt StreamBuffer} is constructed with a {\tt capacity}, which
indicates the maximum number of items it can hold at a given time.  It
is also constructed with a {\tt location}, which indicates the memory
bank in which the buffer is held for its entire lifetime.  The {\tt
address} indicates where the buffer begins in the memory node.  Using
the second constructor, a buffer can also be assigned to a processor,
which means that it is buffered in the processor's registers.  The
{\tt initLength} parameter specifies how many items from memory it
should push into its own representation initially (thereby
incrementing {\tt length} and {\tt totalLength} by {\tt initLength}
during construction).

The {\tt getTotalLength} method returns how many items have been
pushed onto the buffer since the last call to {\tt reset}.  In other
words, {\tt getTotalLength} returns how many elements would be in the
buffer if no storage was ever reused, and it was implemented as a
acyclic list instead of a wrap-around array.  Note that this measure
is unrelated to the capacity of the buffer.  It is also unrelated to
how many items will be written to the buffer in the future; if this
quantity is predictable, then it can be calculated as a function of
the {\tt totalLength} of other buffers.  The reference implementation
of streams in Section~\ref{sec:kerstreams} maintains a totalLength
field that could be directly returned from {\tt StreamBuffer}{\tt
.}{\tt getTotalLength()}.

The values of {\tt getLength()} and {\tt getTotalLength()} are
undefined when a stream buffer is being accessed by a kernel that is
in the RUNNING state.

\sss{Moving Data In and Out of Stream Buffers}
\label{sec:movestream}

For stream buffers to be useful, they need to be initialized with
(possibly non-streaming) data from general-purpose threaded code.
Likewise, the results of a streaming computation need to be used in
the threaded code.  Both of these transfers are done through memory,
via the interface defined by the threaded API.  In particular, device
I/O such as file handling is done using the threaded API, and then
made available to streams through memory.

To enable the threaded-streaming interface to work via memory, each
memory-based stream buffer {\tt s} makes an important guarantee on its
data layout: if {\tt s.getTotalLength()} $\le$ {\tt s.getCapacity()},
then all data items are stored consecutively from the {\tt address} of
the {\tt memLocation} with which the buffer was constructed.  If {\tt
s.getTotalLength()} $>$ {\tt s.getCapacity()}, then there must have
been some reuse of storage, and there is no contract on the data
layout.  Also, there is no contract on data layout at any time if the
{\tt aliased} parameter is false in the {\tt StreamBuffer}'s
constructor, as this represents a case where the high-level compiler
guarantees that no operation will access the locations allocated to
the buffer.  This gives the low-level compiler the freedom to
implement buffers with an architecture-specific representation if
their contents are never aliased.

\subsubsection{Stream Graphs}
\label{sec:streamgraph}

A stream graph represents a set of connected kernels that should be
executed concurrently.  The purpose of a {\tt Graph} is to show the
low-level compiler which pairs of kernels will be simultaneously
reading and writing to a given stream buffer.  That is, the high-level
compiler guarantees that no two kernels will try to access the same
stream object at the same time unless they are in the same graph.
{\small
\begin{verbatim}
  class Graph {
  public:
    // construct graph out of set of kernels.
    Graph(Kernel k1, Kernel kernel2 = 0, ...);

    // calls k.run() on all kernels k in the graph that have k.getStatus()!=RUNNING
    Kernel::STATUS run();

    // calls status() on every kernel in the graph.  Then proceeds as follows:
    //  - if all kernels return FINISHED, then return FINISHED
    //  - if all kernels return UNSTARTED, then return UNSTARTED
    //  - otherwise, consider kernels that did not return FINISHED or UNSTARTED:
    //    - if all of these kernels returned RUNNING, then return RUNNING
    //    - otherwise, return SUSPENDED
    Kernel::STATUS getStatus();

    // blocking method that waits until at least one kernel in the graph 
    // has a status other than RUNNING.  Then, returns getStatus().
    Kernel::STATUS wait();

    // calls terminate() on each kernel in the graph
    void terminate();
  }
\end{verbatim}}
\noindent The connectivity of the kernels in a graph is implicit in
the stream buffers that are shared between the input of one kernel and
the output of another.  The graph does not need to be structured (as
in StreamIt).  However, no two kernels in a graph may read from (or
write to) the same stream buffer.

In a given graph, at most one user-defined kernel can be assigned to a
given processor resource.  (However, pre-defined kernels (see
Section~\ref{sec:predef}) in a graph can be assigned to a resource
with other kernels.)  In addition, the high-level compiler guarantees
that no two kernels from different graphs will try to {\tt run} on the
same resource at the same time.  This restriction applies to both
user-defined and pre-defined kernels.  In order to meet these
restrictions, the high level compiler will either have to merge
neighboring kernels into one, or spread them across multiple graphs.

Each edge of a stream graph can span at most one connection in the
architecture graph.  That is, for each stream buffer that a kernel
writes to, there must be a connection in the architecture graph from
the location of the kernel to the location of the stream buffer.  For
each stream buffer that a kernel reads from, there must be a
connection in the architecture graph from the location of the stream
buffer to the location of the kernel.  (Of course, a kernel can also
be located at the same node as one of its input or output streams; we
assume that self-loops in the architecture graph capture this
property.)

\sss{Executing Graphs}

The control code executes a stream graph by calling its {\tt run}
method.  The graph then calls {\tt run} on each of the component
kernels.  

During the execution of a graph, any interleaving of kernel execution
is valid so long as stream buffers do not overflow or underflow.  In
other words, the low-level compiler can select any schedule respecting
the data dependences of the graphs; no memory analysis is needed.  If
there are location-based dependences due to overlapping streams or
parallel writes, the high-level compiler should insert synchronization
(for inter-graph dependences) or verify that other graph dependences
will ensure a consistent execution order (for intra-graph
dependences).

The high-level compiler might anticipate upcoming kernel executions.
The following method allows this information to be transfered to the
low-level compiler so that the kernel can be loaded into IMEM ahead of
time:
\begin{verbatim}
  // gives a hint to the low-level compiler that it should loading the instructions for
  //  <kernel> at the time of this call, as it is likely to be used in the near future
  void loadKernel(Kernel k);
\end{verbatim}

\sss{Transitioning Between Graphs}

A {\tt Graph} represents only the static sections of the stream graph.
As in the example of Section~\ref{sec:streamover}, dynamic control
flow can surround the construction of graphs and can predicate their
execution.

There are two ways to transfer the outputs of one stream graph to the
inputs of another.  Perhaps the most natural way is to reuse the same
stream buffer in both graphs, thereby carrying over the results; in
our example, stream buffer {\tt s2} is used in multiple graphs.  The
other way to transfer items is by allocating a new input stream that
overlaps with the output stream in memory.  This could be desirable
if, for example, a single output stream is being split between
multiple input streams, all of which are in the local memory of some
processor.  In this case, the control code should indicate that the
kernel reading the new stream is dependent on the kernel that wrote
the original stream; this is done by use of the kernel's {\tt waitFor}
method, thereby saving the low-level compiler from doing
location-based memory analysis to discover dependences between
kernels.

It is also possible for the control processor to inspect and modify
the public fields of a kernel when it is not in the {\tt RUNNING}
state.  Accesses to kernel fields are useful for passing parameters to
subsequent stream graphs, or for retrieving a reduction value from
inside a kernel.  For example: 
{\small
\begin{verbatim}
  // --- kernel code ---
  class SumKernel : public Kernel {
  public:
    IStreamUnordered<int> in;
    int sum;

    SumKernel(IStreamUnordered<int> _in, VM_NODE location, IOBlock<byte> scratch) : 
              Kernel (_in, location, scratch) {
      in = _in;
      sum = 0;
    }

  protected:
    STATUS work() {
      if (in.canPop(1)) {
        sum += in.pop();
        return RUNNING;
      } else {
        return FINISHED;
      }
    }

    void workInfo() {
      KernelInfo.setPop(in, 1);
    }
  }

  // --- control code ---
  StreamBuffer<int> s1(128, SRF, 0x100);
  IOBlock<byte> scratch1(16, SRF, 0x180);

  SumKernel sk(s1, PROC1, scratch1);
  Graph g(sk);
  g.run();
  g.wait();

  int finalSum = sk.sum;
\end{verbatim}}

\sss{Restrictions on Stream Control}

A stream graph can be constructed and executed from general-purpose
threaded code.  In order to facilitate static analysis in the
low-level compiler, there are a number of restrictions on the
statements dealing with stream buffers, kernels, and graphs.  However,
there are no restrictions on non-streaming statements, which can be
finely interleaved with the stream statements; these statements can be
arbitrarily complex threaded code (although, in accordance with the
threaded API, they must adhere to C instead of C++).

The restrictions on stream control code are as follows:

\begin{enumerate}

\item All stream buffer, kernel, and graph variables have a static
single assignment in the program.  This exposes exactly which
constructor is invoked for a given variable name.

\item Architecture resources must be specified by literals when they
are passed to stream, kernel, or graph functions.  That is, constants
denoting processor nodes, memory nodes, memory addresses, stream
capacities, connections, and channels must be passed to API functions
directly, rather than passing the value in a variable.  Similarly,
identifiers of objects can only be used in three contexts: 1) on the
left hand side of their assignment, 2) as the direct target of a
method call, and 3) as an argument to a function.  This ensures that
all references to streams, kernels, and graphs are resolvable by the
low-level compiler.

\item There are no references to templates or objects besides the
classes described in this document.

\item Any function that contains a reference to a stream, kernel, or
graph object must NOT be recursive.

\end{enumerate}

\subsubsection{Pre-Defined Kernels}
\label{sec:predef}

All memory management and network support for streams are integrated
into the graph model of Section~\ref{sec:streamgraph}.  This is done
using pre-defined kernels that can connect streams in different
memories, or route streams to network channels.

\subsubsection*{Memory Management Kernels}

\ssss{Copy} The primary use of this kernel is for copying items
between streams in different memory banks, though it can also be used
for copying between streams in a single memory.
{\small
\begin{verbatim}
  template <class T>
  class Copy : public Kernel {
  public:
    Copy(VM_NODE location, IStream<T> srcStr, OStream<T> destStr, int length = ENTIRE_STREAM);
  }
\end{verbatim}}
The {\tt length} indicates how many words should be transferred; by
default, all elements in the {\tt srcStr} are copied.

\ssss{Scatter/Gather} A set of scatter and gather kernels allow copies
between non-contiguous elements of streams.  The strided kernels are
for copying regularly spaced chunks into or out of a block:
{\small
\begin{verbatim}
  template <class T>
  class StridedScatter : public Kernel {
  public:
    StridedScatter(VM_NODE location, IStream<T> srcStr, OBlock<T> destBlock, int length,
                   int destStride = 1, int itemsPerChunk = 1);
  }

  template <class T>
  class StridedGather : public Kernel {
  public:
    StridedGather(VM_NODE location, IBlock<T> srcBlock, OStream<T> destStr, int length,
                  int srcStride = 1, int itemsPerChunk = 1);
  }  
\end{verbatim}}
The above kernels copy items in segments of {\tt itemsPerChunk} items.
The {\tt srcStride} or {\tt destStride} indicates the number of items
between the start of adjacent chunks, while {\tt length} represents
the number of items that should be copied.

The indexed scatter and gather kernels allow irregular accesses to a
source or destination block:
{\small
\begin{verbatim}
  template <class T>
  class IndexedScatter : public Kernel {
  public:
    IndexedScatter(VM_NODE location, IStream<T> srcStr, IStream<int> indexStr, OBlock<T> destBlock, 
                   int length, int itemsPerChunk = 1);
  }

  template <class T>
  class IndexedGather : public Kernel {
  public:
    IndexedGather(VM_NODE location, IBlock<T> srcBlock, IStream<int> indexStr, OStream<T> destStr, 
                  int length, int itemsPerChunk = 1);
  }  
\end{verbatim}}
In the {\tt IndexedScatter} kernel, the {\tt indexStr} indicates the
positions in the output stream at which the records should be written;
in the {\tt IndexedGather} kernel, the {\tt indexStr} indicates the
positions in the input stream at which the records should be read.
The {\tt length} argument indicates the number of items that should be
copied.

\subsubsection*{Network Kernels}

The network kernels are for synchronized communication between
resources.

\ssss{Send} The {\tt Send} kernel sends a stream from one processor to
another, subject to the connection protocol described below.
{\small
\begin{verbatim}
  template <class T>
  class Send : public Kernel {
  public:
    // send <srcStr> on <channel> of <connection>
    Send(VM_NODE location, IStream<T> srcStr,  VM_EDGE connection, int channel);
  }
\end{verbatim}}
Since the kernel is executing on processor {\tt location}, we require
that {\tt connection} is an edge from {\tt location} to a neighboring
processor.

\ssss{Receive} The {\tt Receive} kernel receives a stream from a
neighboring processor, subject to the connection protocol described
below.  
{\small
\begin{verbatim}
  template <class T>
  class Receive : public Kernel {
  public:
    // receive <destStr> from <channel> of <connection>.
    Receive(VM_NODE location, OStream<T> destStr,  VM_EDGE connection, int channel);
  }  
\end{verbatim}}
Since the kernel is executing on processor {\tt location}, we require
that {\tt connection} is an edge into {\tt location} from a
neighboring processor.

\ssss{Send/Receive Protocol} We refer to channel number $n$ of
connection $c$ as the pair $(c, n)$.  Note that $n$ is a virtual
channel identifier; $n$ does not need to fall within $[0,
\mbox{VM\_PROP\_CHAN\_NUM}]$ for connection $c$.  Rather, the
communication protocol will ensure that there are less than
VM\_PROP\_CHAN\_NUM active channels at a time.

The protocol maintains a queue of {\tt Send} and {\tt Receive} kernels
that are waiting to communicate across each $(c, n)$; let them be
$\mt{SendQ}(c, n)$ and $\mt{ReceiveQ}(c, n)$, respectively.  Kernels
are pushed onto these queues in the same order that they are executed
from the stream processor API.  We disallow the case where multiple
kernels in a given graph are targeting the same queue.  Thus, the
order of the kernels in the queues is well-defined\footnote{Unless
there are multiple threads executing on the control processor, in
which case synchronization should be used to ensure a deterministic
ordering of the send/receive kernels across threads.}.

To open a new session of data transfer across $(c, n)$, the following
conditions must be met:
\begin{enumerate}

\item Channel $n$ is {\it free} on connection $c$.  That is, no other
session is open on $(c, n)$, and $c$ has room for another active
channel.

\item $\mt{SendQ}(c, n)$ and $\mt{ReceiveQ}(c, n)$ are non-empty.

\end{enumerate}
If these conditions are satisfied, then a new session is opened
between the kernels at the front of $\mt{SendQ}(c, n)$ and
$\mt{ReceiveQ}(c, n)$.  Items are transmitted across the channel until
either the {\tt Send} kernel or the {\tt Receive} kernel goes into the
FINISHED state.  At this point, {\tt terminate} is called on both
kernels, and they are removed from the respective queues for $(c, n)$.
The session on $(c, n)$ is finished.

Note that until a session is opened, all pending kernels are blocked.
The graphs that contain these kernels could possibly execute other
nodes, but the {\tt Send} or {\tt Receive} nodes must wait until the
channel is ready.

\subsubsection*{Example}

We consider one more example to illustrate the use of the above
kernels.  In this example, there are two processors that each contain
their own memory:

\begin{figure}[h]
\begin{center}
\psfig{figure=ex1.eps,width=1.8in}
\end{center}
\vspace{-12pt}
\end{figure}

The application does audio segmentation on a series of 10 input files
and plays a summary of each file on a speaker.  The first processor
does the segmentation itself, while the second processor filters the
extracted segments to provide a smooth transition between them.

{\small
\begin{verbatim}
  // --- code for PROC1 ---

  for (int i=0; i<10; i++) {
    // read file and put in memory (not part of SVM API)
    int fileLength = readFile(filename[i], 10000, MEM1, 0x1000);

    // allocate overlapping stream in memory for raw data
    StreamBuffer<float> rawStr(fileLength, MEM1, 0x1000, fileLength), 
    // also allocate block for gather operation
    IOBlock<float> rawBlock(fileLength, MEM1, 0x1000), 

    // allocate other streams
    StreamBuffer<float> segIndices(10, PROC1), sumData(10, PROC1);
    IOBlock<byte> scratch1(128, MEM1, 0x4000);

    Kernel k1 = new ExtractSegments(PROC1, scratch1,               // make indices of summary segments
                                    rawStr, segIndices);
    Kernel k2 = new Gather<float>(rawBlock, segIndices, sumData),  // gather summary audio in sumData
    Kernel k3 = new Send<float>(PROC1, sumData, c1, 3);            // send over connection c1, channel 3
    Graph g(k1, k2, k3);
            
    g.run();                                                       // run for whole length of file
    g.wait();
  }

  // --- code for PROC2 ---

  for (int i=0; i<10; i++) {
    stream<float> sumData(128, MEM2, 0x2000), smoothData(100, MEM2, 0x2080);
    stream<byte> scratch2(128, MEM2, 0x2160);

    Kernel k1 = new Receive(PROC2, sumData, c1, 3),                // receive summaries over channel
    Kernel k2 = new FIRFilter(PROC2, scratch,                      // filter summaries
                              sumData, smoothData);
    Kernel k3 = new Speaker(smoothData);                           // send to speaker
    Graph g(k1, k2, k3);

    g.run();
    g.wait();
  }   
\end{verbatim}}
In processor 1, a {\tt Gather} kernel is used to load the audio file
at the indices where the summary segments appear.  The {\tt Gather}
kernel is directly connected to a {\tt Send} kernel which sends the
summary segments across virtual channel 3 of connection {\tt c1}.
Processor 2 uses a {\tt Receive} kernel to receive the summary
segments before filtering them and sending them to a speaker.  Note
that there are 10 sessions of data transfer between the processors,
and the amount of data transferred during each session depends on the
length of the audio file; a session is finished when processor 1
finishes executing its stream graph.

\subsubsection{Architecture Specific Kernels}
\label{sec:library}

The API supports architecture specific library routines via black-box
kernels that are defined in the metadata and then instantiated by name
in the stream control code.  These kernels are identical to
user-defined kernels, except that they have no {\tt work} and {\tt
prework} functions; instead, they are recognized by the low-level
compiler for the architecture and are translated into hand-optimized
library code or architecture-specific directives.  The kernels should
include {\tt workInfo} and {\tt preworkInfo}, however, so that the
high-level compiler can judge how many items will be consumed in each
firing (in case it wants to specify an iteration count for {\tt
Graph.run}).

To ensure that the low-level compiler can recognize an
architecture-specific kernel, the high-level compiler guarantees that
it will not merge architecture-specific kernels with other kernels, or
rename the kernel so that it would become unrecognizable to the
low-level compiler.

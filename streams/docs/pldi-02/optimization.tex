\section{Optimization}

We now turn our attention to the problem of optimizing a stream
program.  Unlike other program domains, where the principle aim of
compiler optimization is to shorten the total execution time, there
are many distinct optimization metrics for streaming applications,
including throughput, latency, data size, and code size.  The latter
two of these are especially important in embedded domains, where
memory is in short supply; latency can be critical for real-time
applications, and throughput is always of interest.

% here's a more verbose version...
%
%These include: 1) {\bf Throughput}, the number of items passing
%through the stream per unit time, 2) {\bf Latency}, the amount of
%elapsed time (or consumed data) before the effects of an input item
%are seen at the output, 3) {\bf Data size}, the buffer space required
%to hold live items, and 4) {\bf Code size}, the space consumed by
%instructions.

In this section we present some transformations that improve a stream
program by one or more of these metrics.  However, there is often a
tradeoff between throughput and latency, or code size and data size,
such that the optimality of a stream program depends on the metric of
interest.

\subsection{Fusion}

A primary stream optimization is the fusion of multiple filters and
streams into a single atomic unit.  This can be beneficial for
throughput, latency, and data size, as data buffers are eliminated in
favor of local variables with short live ranges.  Fusion is also
important for adapting a fine-grained stream program to a
coarse-grained target; the programmer benefits from dividing the
program into many modular components without losing the performance of
a single, integrated procedure.

An algorithm for fusing a pipeline of two filters that contain only {\tt
push} and {\tt pop} statements is given in \cite{pro96}.  However, in a
stream program, it pays to consider not only vertical fusion of pipeline
constructs, but also horizontal fusion of parallel streams in a
SplitJoin.  Here we present a transformation on the abstract syntax of
Section \ref{sec:intalgebra} that collapses a SplitJoin construct
containing $n$ parallel filters $s1 \dots sn$ into a single filter $sc$.
Let us denote the weights of the joiner $J$ by $w_1 \dots w_n$ with $W =
\sum_{i=1}^{n}{w_i}$:
\begin{align*}
Merge[(S~s1~\dots&~sn~J)] = (Filter~push_{sc}~pop_{sc}~peek_{sc}~work_{sc}) \\
where: {\bf push_{sc}} &= totalRounds * W \\
       {\bf pop_{sc}} &= totalPop ~~~~~~~~~if~S~=~WeightedRR \\
                &= totalPop / n ~~~~~if~S~=~Duplicate \\
       {\bf peek_{sc}} &= MAX_{j \in [1,push_{sc}]}(shift(peek_{sj}, j)) \\
       {\bf work_{sc}} &= f_{sc, 1} \dots f_{sc, push_{sc}} \\
       totalRounds &= lcm(lcm(push_{s1}, w_1), \dots, lcm(push_{sn},
       w_n)) \\
       rounds_i &= totalRounds * w_i  / push_{si} \\
       totalPop &= \sum_{i=1}^{n}(rounds_i*pop_i) \\
       shift(x, j) &= \mi{I_S}{I_{sj}}(g(i_{local})+ \\ &~~~~~(\mi{I_{sj}}{O_{sj}} \circ \mi{O_{sj}}{O_J})(j)-peek_{sj}) \\
       f_{sc, j} &= g \ra f_{s~p(j)}(i_{local} \ra shift(g(i_{local}, j)))
\end{align*}
We have proven that this transformation preserves the meaning of the
program with respect to our transform algebra for the case when $n = 2$,
$w_1 = w_2 = 1$, and $S$ is a duplicate splitter.  The proof is by
straightforward algebra, but we omit it due to space constraints; we
expect that the general proof is also straightforward.

\subsection{Fission}

filter fission with state propagation
fission of a feedback loop

\subsection{Steady-state Invariant code motion}

steady-state invariant code motion

\subsection{Decimation Removal}

\subsection{Data Parallelization}

Data Parallelization
-	MMX
-	Raw


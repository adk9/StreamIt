\begin{figure}
\centering
\psfig{figure=tapes.eps,width=3.2in}
\caption{A filter's input and output tapes during an execution step.
With each step, the filter pushes two items, pops two items, and peeks
at three additional items.  The initial state of the input tape is
shown at left.  The center shows the filter with both input and output
tapes during the invocation of {\tt work}.  The final state of the
output tape is shown at right.}
\label{fig:tape}
\end{figure}

\begin{figure}
\centering
\psfig{figure=pipeline.eps,width=2.0in}

(a) A Stream. \\
\vspace{8pt}
\psfig{figure=splitjoin.eps,width=3.2in}

(b) A SplitJoin. \\
\vspace{8pt}
\psfig{figure=feedback.eps,width=3.2in}

(c) A FeedbackLoop. \\
\vspace{8pt}
\caption{Tape labeling for StreamIt structures.}
\label{fig:tapelabels}
\end{figure}

\section{Streaming Model of Computation}

In this section, we develop an abstract model of streaming computation
to serve as a basis for reasoning about program transformations and
compilation techniques within the streaming domain.  A stream graph
differs from a traditional, sequential program in that all of the
filters of the graph are implicitly running in parallel, with the
execution order constrained only by the availability of data on
channels between the filters.  Further, filters communicate only with
their immediate neighbors, thereby removing any notion of global time
or non-local dependences of one filter on another.  [add idea that it
is the specification of the atomic work function that really prevents
global time] These properties merit the development of a new model of
computation, in which the notions of timing, scheduling, and
dependence analysis are in terms that are relative to a given filter
in the graph, instead of being global characteristics of a program.

In Section \ref{minfunc}, we develop a transfer function that provides
the basis for distributed time in a stream graph... [build operational
semantics to give a precise meaning to messaging, and denotational
semantics to validate program transformations].

\subsection{Notation}

We use the following notation:

\begin{itemize}

\item A {\it tape} is an infinite history of the values that have been
  pushed onto a channel between two filters (see Figure
  \ref{fig:tapes}).  We use $I_A$ and $O_A$ to denote the input and
  output tapes of filter $A$, respectively, with numbering used to
  distinguish between multiple input or output tapes (see Figure
  \ref{tapelabels}).  Finally, $n(T)$ represents the number of items
  on tape $T$ at a given point of execution.  [should we define $p(T)$
  here or wait until we use it?  long time def-use!]

\item We say that filter $A$ is {\it upstream} of filter $B$ (or,
  equivalently, $B$ is {\it downstream} $A$) if there is a directed
  path in the stream graph from $O_A$ to $I_B$.

\item The number of items that are pushed, popped, and peeked by
  filter $A$ during a single execution of its work function are
  denoted by $push_A$, $pop_A$, and $peek_A$, respectively.  Note that
  $peek_A$ includes the items that are popped, such that $pop_A \le
  peek_A$.

\end{itemize}

\subsection{Relative Time}
\label{sec:minfunc}

As outlined above, there is no concept of global time in a stream
graph since each filter is completely independent and can only
communicate with its neighbors through input and output channels.
Thus, if two filters need to synchronize an event, the synchronization
must be in terms of the data items that are passed over a channel.

In this context, we define a $min$ function between tapes in the
stream graph that allows disconnected filters to have a common notion
of time.  The function is defined in terms of data dependence:
\begin{definition}
$\mi{a}{b}(x)$ is the minimum number of items that must appear on tape
$a$ given that there are $x$ items on tape $b$.
\end{definition}

We now turn to deriving $\mi{a}{b}$ for all pairs of tapes $a$ and $b$
in a filter graph where $a$ is upstream of $b$.

\subsubsection{Filters}

Let us derive $\mi{I_A}{O_A}(x)$, which represents the time shift
across a single filter $A$.  Since the filter produces $push_A$ items
on every invocation, it must be invoked
$\left\lceil\frac{x}{push_A}\right\rceil$ to produce the $x$'th item.
On each invocation, it consumes $pop_A$ items, and peeks at an
additional $peek_A-pop_A$ items.  Thus, the total number of items that
must be present on the input is:
\begin{align*}
\mi{I_A}{O_A}(x) = \left\lceil\frac{x}{push_A}\right\rceil*pop_A+(peek_A-pop_A)
\end{align*}

\subsubsection{Pipelines}

Let us now derive an expression for $min$ in the case of a pipeline.
In the base case, consider that two filters are connected, with the
output of $A$ feeding into the input of $B$ (see
Figure~\ref{fig:tapelabels}).  We are seeking $\mi{I_A}{O_B}(x)$: the
minimum number of items that must appear on tape $I_A$ given that
there are $x$ items on tape $O_B$.  Observing that a minimum of
$\mi{I_B}{O_B}(x)$ items must appear on tape $I_B$, and that $I_B$
must equal $O_A$ since the filters are connected, we see that a
minimum of $\mi{I_A}{O_A}(\ma{I_B}{O_B}(x))$ items must appear on
$I_A$:
\begin{align*}
\ma{I_A}{O_B} = \mi{I_A}{O_A} \circ \mi{I_B}{O_B}
\end{align*}
By identical reasoning, this composition law holds for pipelined
streams as well as filters.  That is, given tapes $x$, $y$, and $z$,
we have that:
\begin{align}
\label{eq:compose}
\mi{x}{z} &= \mi{x}{y} \circ \mi{y}{z}
\end{align}
However, there is a restriction on this definition.  It only applies
when there is a downstream path $P_1$ from the filter following $x$ to
the filter preceding $y$, a downstream path $P_2$ from the filter
following $y$ to the filter preceding $z$, and the paths $P_1$ and
$P_2$ are non-overlapping.  This restriction prevents the successive
composition of transfer functions around feedback loops, thereby
ensuring a unique definition for all pairs $(x, z)$ where there is a
downstream path from $x$ to $z$.

\subsubsection{SplitJoins}

\subsubsection{FeedbackLoops}

%% \subsubsection{SplitJoins}

%% We now derive $min$ and $max$ in the case of a SplitJoin, as pictured
%% in Figure \ref{splitjoin}.  For the splitter $S$ there are two output
%% tapes; let us denote them by $O1_S$ and $O2_S$.  Similarly, let us
%% denote the two input tapes of the joiner $J$ by $I1_J$ and $I2_J$.  We
%% derive below the transfer functions the round robin and
%% duplicate/combine nodes.  Note that the duplicate/combine nodes can be
%% simulated with round robins and duplicating filters, but we provide
%% the transfer functions anyways to simplify the semantic analysis of a
%% program.  We have yet to derive these expressions for the weighted
%% round robin nodes.

%% {\bf Round robin splitter.}  In the case of a round-robin splitter, the
%% items from the input tape are alternately routed to the output tapes,
%% with the first item going onto tape $O1_S$.  By this definition, we
%% can see that the splitter's $max$ is defined as follows:
%% \begin{align*}
%% \ma{I_S}{O1_S}(x) &= \left\lceil\frac{x}{2}\right\rceil \\
%% \ma{I_S}{O2_S}(x) &= \left\lfloor\frac{x}{2}\right\rfloor
%% \end{align*}
%% To derive the $min$ function across a splitter, observe that the input
%% tape need only progress so far as to produce the items on the emptier
%% output tape.  That is, we need to consider the number of items on both
%% of the splitter's output to determine the minimum number of items that
%% are needed at its input.  Thus, our $min$ function has two arguments:
%% the first corresponding to $O1_S$ and the second corresponding to
%% $O2_S$.  The equation is as follows:
%% \begin{align*}
%% \mi{I_S}{(O1_S, O2_S)}(x_1, x_2) = MIN(2*x_1-1, 2*x_2)
%% \end{align*}
%% {\bf Round robin joiner.}  The rules for a round robin joiner are in
%% some sense dual to those of the round robin splitter.  Again assuming
%% that items are alternately drawn from the input tapes, starting with
%% $I1_J$, we have that:
%% \begin{align*}
%% \mi{I1_J}{O_J}(x) &= \left\lceil\frac{x}{2}\right\rceil \\
%% \mi{I2_J}{O_J}(x) &= \left\lfloor\frac{x}{2}\right\rfloor
%% \end{align*}
%% Again, the $max$ function takes two arguments, corresponding to the
%% number of items on $I1_J$ and $I2_J$, respectively:
%% \begin{align*}
%% \ma{(I1_J, I2_J)}{O_J}(x_1, x_2) = MIN(2*x_1-1, 2*x_2)
%% \end{align*}
%% {\bf Duplicate splitter}.  Clearly, the $max$ function of a duplicate
%% splitter is simply the identity function, since it maps each element
%% on the input tape to the same location on the output tapes:
%% \begin{align*}
%% \ma{I_S}{O1_S}(x) &= x \\
%% \ma{I_S}{O2_S}(x) &= x
%% \end{align*}
%% The $min$ function is similar, except that--like the round robin
%% split--the input need only progress as far as the lesser output:
%% \begin{align*}
%% \mi{I_S}{(O1_S, O2_S)}(x_1, x_2) = MIN(x_1, x_2)
%% \end{align*}
%% {\bf Combine joiner.} The combine joiner is simply the dual of the
%% duplicate splitter, with transfer functions that the reader can verify
%% as follows:
%% \begin{align*}
%% \ma{(I1_J, I2_J)}{O_J}(x_1, x_2) &= MIN(x_1, x_2) \\
%% \mi{I1_J}{O_J}(x) &= x \\
%% \mi{I2_J}{O_J}(x) &= x
%% \end{align*}

%% \subsubsection{FeedbackLoops}

%% \begin{figure}
%% \centering
%% \psfig{figure=feedback.eps,width=3.2in}
%% \caption{\protect\small  FeedbackLoop construct with labeling.
%% \protect\label{looplabel}}
%% \end{figure}

%% We have to be careful when defining the transfer functions for
%% feedback loops (see Figure \ref{looplabel}).  The feedback splitter
%% $FS$ serves as a normal splitter, and has the same $min$ and $max$
%% functions as defined above.  However, the feedback joiner $FJ$ is
%% slightly different than a standard joiner, since during the first few
%% executions it fabricates values from the loop body before they appear
%% on the input tape.  The transfer function must take special account of
%% these initial values, since they never appear on $I2_{FJ}$, the input
%% tape from the loop body.  This is because we model the initialization
%% of FeedbackLoops by feeding the joiner the initial values directly
%% instead of pushing them onto a channel.

%% Let $n$ be the number of initial values that are provided to the
%% feedback joiner before values from the feedback loop are read.  Let
%% $J$ be a normal COMBINE or ROUND\_ROBIN joiner as defined for
%% SplitJoins.  Now, let us define the transfer functions for $FJ$, the
%% feedback joiner.

%% The $min$ function for the main stream is as before:
%% \begin{align*}
%% \mi{I1_{FJ}}{O_{FJ}} = \mi{I1_J}{O_J} 
%% \end{align*}
%% However, we must offset by $n$ when considering the $min$ function
%% that draws from the loop's tape:
%% \begin{align*}
%% \mi{I2_{FJ}}{O_{FJ}}(x) = \mi{I2_J}{O_J}(x) - n
%% \end{align*}
%% Finally, the $max$ function must be similarly shifted for the input
%% from the loop:
%% \begin{align*}
%% \ma{(I1_{FJ}, I2_{FJ})}{O_{FJ}}(x_1, x_2) = \ma{(I1_J, I2_J)}{O_J}(x_1,
%% x_2 + n)
%% \end{align*}

\subsubsection{Program Verification}

Borrow from program verification section of last paper. 

\subsection{Message Timing}

in the previous description of streamit, the messaging system was left
unspecified.  here we use the min function to give a precise semantics
to message delivery timing in streamit.  this will yield an
operational semantics to the scheduling of streamit programs.

\subsection{Operational Semantics}

\subsection{Denotational Semantics}

assume for now that the filters are stateless.

the above discussion addresses the order in which filters can be
executed, but does not address the values on the tapes, or the meaning
of a program as a whole.  for this we turn to a denotational
semantics, which will allow us to prove the equivalence of two
different stream programs.

in the denotaional semantics, we'll represent a filter as follows:

1. push, pop, (max items peeked)
2. the functions specifying the output values as a function of the
input values.

3. this set of functions...

ii. how to map a given textual representation into a canonical
representation.

iii. how to represent the canonical representation in the functinal
format

iv. further, to help automate program transformations, we can talk
about translationg from the functional format to the canonical
representation.  talk about CSE from reconstruction

in the next sections, we'll appeal to this denotational semantics in
argueing for the correctness of program transformations.

\section{Optimization}

then discuss a few optimizations with the denotational semantics to
prove that they are correct


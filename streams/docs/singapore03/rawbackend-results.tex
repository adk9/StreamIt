\subsection{Preliminary Results}
\label{sec:results}

\begin{table*}[!t]
\begin{center}
\scriptsize
\begin{tabular}{|l|l||r||r|r|r|r||r||} \hline
 & & {\bf lines of} & \multicolumn{4}{|c||}{\bf \# of constructs in the program} & {\bf \# of filters in the} \\ \cline{4-7}
{\bf Benchmark} & {\bf Description} & {\bf code} & filters & pipelines & splitjoins & feedbackloops & {\bf expanded graph}
\\
\hline \hline
FIR & 64 tap FIR & 
125 & 5 & 1 & 0 & 0 & 132
\\ \hline
Radar & Radar array front-end~\cite{pca} & 
549 & 8 & 3 & 6 & 0 & 52
\\ \hline
Radio & FM Radio with an equalizer & 
525& 14 & 6 & 4 & 0 & 26
\\ \hline
Sort & 32 element Bitonic Sort & 
419 & 4 & 5 & 6 & 0 & 242
\\  \hline
FFT & 64 element FFT & 
200 & 3 & 3 & 2 & 0 & 24
\\  \hline
Filterbank & 8 channel Filterbank & 
650 & 9 & 3 & 1 & 1 & 51
\\  \hline
GSM & GSM Decoder & 
2261 & 26 & 11 & 7 & 2 & 46
\\ \hline
Vocoder & 28 channel Vocoder~\cite{seneff80} &  
1964 & 55 & 8 & 12 & 1 & 101
\\ \hline
3GPP & 3GPP Radio Access Protocol~\cite{3gpp} &  
1087 & 16 & 10 & 18 & 0 & 48
\\ \hline
\hline
\end{tabular}
\caption{\protect\small Application Characteristics.}
\label{tab:benchmarks}
\end{center}
\end{table*}

\begin{table*}[!t]
\begin{center}
\scriptsize
\begin{tabular}{|l||r|r|r|r||r||r||} \hline
& \multicolumn{5}{|c||}{\bf 250 MHz Raw processor} & {\bf C on a 2.2 GHz} \\ 
\cline{2-6} 
{\bf Benchmark} & \multicolumn{4}{|c||}{\bf StreamIt on 16 tiles} & {\bf C on a single tile} & {\bf Intel Pentium IV}\\ 
\cline{2-7}
& {\bf Utilization} &
\begin{tabular}{c}\hspace{-5pt} {\bf \# of tiles} \hspace{-5pt}\\
\hspace{-5pt} {\bf used} \hspace{-5pt}
\end{tabular} &    
 {\bf MFLOPS} & 
\begin{tabular}{c}\hspace{-5pt} {\bf Throughput} \hspace{-5pt}\\
\hspace{-5pt} {\bf (per 10$^5$ cycles)} \hspace{-5pt}
\end{tabular} &    
\begin{tabular}{c}\hspace{-5pt} {\bf Throughput} \hspace{-5pt}\\
\hspace{-5pt} {\bf (per 10$^5$ cycles)} \hspace{-5pt}
\end{tabular} &    
\begin{tabular}{c}\hspace{-5pt} {\bf Throughput} \hspace{-5pt}\\
\hspace{-5pt} {\bf (per 10$^5$ cycles)} \hspace{-5pt}
\end{tabular} \\    
\hline \hline
FIR    & 84\% &  14 & 815 &  1188.1  & 293.5 & 445.6 \\ \hline
Radar  & 79\% & 16 & 1,231 &     0.52  & {\it app. too large} & 0.041 \\ \hline
Radio  & 73\% & 16 & 421 &    53.9  & 8.85 & 14.1 \\ \hline
Sort   & 64\% & 16  & N/A &  2,664.4 & 225.6 & 239.4 \\ \hline
FFT    & 42\% & 16  & 182 &  2,141.9 & 468.9 & 448.5  \\ \hline
Filterbank & 
       41\% & 16  &  644 &   256.4  & 8.9 & 7.0   \\ \hline
GSM    & 23\% & 16 & N/A &    80.9  & {\it app. too large} & 7.76 \\ \hline
Vocoder& 17\% & 15  & 118 &     8.74  & {\it app. too large} & 3.35  \\ \hline
3GPP   & 18\% & 16  & 44 &   119.6  & 17.3  & 65.7   \\ \hline \hline
\end{tabular}
\caption{\protect\small Performance Results.}
\label{tab:performance}
\end{center}
\end{table*}

We evaluate the StreamIt compiler for the set of applications shown in
Table~\ref{tab:benchmarks}; our results appear in
Table~\ref{tab:performance}.

%  For each benchmark, we show the number of
%lines of StreamIt code, the occurrence of each stream construct, and
%the number of nodes required to execute the expanded graph on Raw.
For each application, we compare the throughput of StreamIt with a
hand-written C program, running the latter on either a single tile of
Raw or on a Pentium IV.  For Radio, GSM, and Vocoder, the C source
code was obtained from a third party; in other cases, we wrote a C
implementation following a reference algorithm.  For each benchmark,
we show MFLOPS (which is N/A for integer applications), processor
utilization (the percentage of time that an {\it occupied tile} is not
blocked on a send or receive), and throughput.  We also show the
performance of the C code, which is not available for C programs that
did not fit onto a single Raw tile (Radar, GSM, and Vocoder).
Figures~\ref{fig:compare-raw} and~\ref{fig:compare-pentium} illustrate
the speedups obtained by StreamIt compared to the C
implementations\footnote{FFT and Filterbank perform better on a Raw
tile than on the Pentium 4.  This could be because Raw's single-issue
processor has a larger data cache and a shorter processor pipeline.}.

The results are encouraging.  In many cases, the StreamIt compiler
obtains good processor utilization--over 60\% for four benchmarks and
over 40\% for two additional ones.  For GSM, parallelism is limited by
a feedbackloop that sequentializes much of the application.  Vocoder
is hindered by our work estimation phase, which has yet to accurately
model the cost of library calls such as {\tt sin} and {\tt tan}; this
impacts the partitioning algorithm and thus the load balancing.  3GPP
also has difficulties with load balancing, in part because our current
implementation fuses all the children of a stream construct at once.

StreamIt performs respectably compared to the C implementations,
although there is room for improvement.  The aim of StreamIt is to
provide a higher level of abstraction than C without sacrificing
performance.  Our current implementation has taken a large step
towards this goal.  For instance, the synchronization removal
optimization improves the throughput of 3GPP by a factor of 1.8 on 16
tiles (and by a factor of 2.5 on 64 tiles.)  Also, our partitioner can
be very effective--as illustrated in Figure~\ref{fig:beam-blood},
partitioning the Radar application improves performance by a factor
of 2.3 even though it executes on less than one third of the tiles.

\begin{figure*}[!t]
\centering
\begin{minipage}{3.0in}
\centering
\psfig{figure=speedup-graph.eps,width=2.95in}
\caption{\protect\small StreamIt throughput on a 16-tile Raw machine,
normalized to throughput of hand-written C running on a single Raw
tile.  \protect\label{fig:compare-raw}}
\end{minipage}
~
\hspace{0.1in}
\begin{minipage}{3.0in}
\centering
\psfig{figure=throughput-graph.eps,width=2.95in}
\caption{Throughput of StreamIt code running on 16 tiles and C code
running on a single tile, normalized to throughput of C code on a
Pentium IV. \protect\label{fig:compare-pentium}}
\end{minipage}
\end{figure*}

The StreamIt optimization framework is far from complete, and the
numbers presented here represent a first step rather than an upper
bound on our performance.  We are actively implementing aggressive
inter-node optimizations and more sophisticated partitioning
strategies that will bring us closer to achieving linear speedups for
programs with abundant parallelism.


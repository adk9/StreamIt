\section{Results}
We chose to measure the strength of our optimizations in terms of 
floating point instruction reduction. The StreamIt compiler currently
has two code generation backends. The uniprocessor backend generates sequential C code
that can be compiled and linked against a supporting library. 
There is also a backend that generates code for the RAW microprocessor
\cite{waingold97baring, raw-micro}, which features
a grid of processors interconnected via various communication facilities. 
Mapping a StreamIt program on to the RAW architecture is complicated
by issues of communication, load balancing and partitioning\cite{streamit-asplos}. 
Therefore, the effects of our linear analysis optimizations can not
be easily differentiated from differences in placement, routing and fusion that result
from modifying the program's stream graph (as is the case for linear replacement). 
Therefore we chose to use the uniprocessor backend for our measurements.

\subsection{Measurement Methodology}
As always, the appropriate metric to measure performance is not totally clear. 
Running time is complicated by the multitasking environment offered by 
modern operating systems. Also, given that the uniprocessor backend for
the StreamIt compiler is meant for prototyping, the supporting 
library is anything but optimized. Therefore, measuring running time is
probably not an appropriate metric.

The fundamental metric of processing performance is amount of computation, and since
our optimizations are both aimed at reducing the amount of computation we will focus 
on that reduction in our results section. Most of the applications that are and will
be written in StreamIt process floating point data with floating point instructions (FLOPs), 
and so reducing their number is good for overall performance. 
Therefore, we chose the reduction in FLOPs as our measurement metric executed.

Our measurement platform was a Dual Intel 2.2 GHz P4 Xenon processor system 
running Linux. We compiled the benchmark programs using StreamIt's uniprocessor
and compiled the resulting C code with {\tt gcc}, with {\tt -O2} optimization.

Obviously statically counting the number of FLOPs in a program is not helpful. We 
need to measure the number of floating point instructions that are executed at runtime.
To do measure FLOPs dynamically, we utilized the DynamoRIO\cite{rio-webpage}
runtime introspection and optimization infrastructure. Using a simple DynamoRIO application 
we instrumented each benchmark program at runtime and counted the number of FLOPs executed.


We define three instruction types of interest for the Intel x86 instruction set:
\begin{itemize}
\item[flops] Any opcode whose name that begins with {\tt f} in the x86 instruction set.
\item[fadds] Any of ({\tt fadd faddp fiaddp fsub fsubp fisubp fsubr fsubrp fisubr}).
\item[fadds] Any of ({\tt fmul fmulp fimulp fdiv fdivp fidivp fdivr fdivrp fidivr}).
\end{itemize}

There are no standard benchmark written for StreamIt, so we had to assemble
a set of programs which perform computations that are likely to be representative
real world applications. We settled on a set of six, which we describe below.

\begin{enumerate}
\item FilterBank: Implements a multi-rate signal decomposition processing block which is common in communications and image processing.
\item FIR: A single 100 point FIR filter which implements a low pass filter with cutoff frequency $\omega_c=\frac{\pi}{3}$
\item FMRadio: Implements an FM demodulator in software.
\item RateConverter: Converts a sampling rate $f_{s1}=\frac{1}{T}$ to $f_{s2}=\frac{3}{2T}$.
\item TargetDetect: Four matched filters perform threshold target detection in parallel.
\item Radar: radar frontend, beamformer and target detection.
\end{enumerate}


\subsection{Frequency Replacement Scaling}
\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/frequency-win.eps}
\caption{Plot showing number of multplications for the frequency transformation over the number of multiplications for direct convolution per output as a function of $M$ and $N$. $N$ and $M$ are the normalized size of the FIR filter and output window size, respectively. Numbers less than one indicate a multiplication reduction, and numbers more than one indicate an increase in multiplication.}
\label{fig:frequency-win}
\end{figure}

In this section we describe the results we expect for the frequency transformation. We
define $M$ as the number of FIR coefficients, and $N$ as the number of outputs produced. Direct 
convolution requires $O(MN)$ multiplies to generate $N$ output values 
(eg $M$ multiplies per output). To produce $N$ output values using the frequency transformation 
requires $O((M+N)lg(M+N))$ multiplications for both the FFT and IFFT and $O(M+N)$ 
multiplications to implement the complex coefficient multiplication in the frequency domain.
Therefore, the number of multiplications per output for the frequency transformation
normalized the the number of multiplications per output with direct convolution is
$f(M,N)=\frac{O((M+N)lg(M+N))}{O(MN)}$. Figure~\ref{fig:frequency-win} plots this function
in normalized $M$, $N$ space. It is interesting to note that if $M$ or $N$ is held constant 
and the other is increased, $F(M,N)$ first decreases and then increases. Given that our compiler
can choose $N$, we need to choose an $M$ that is roughly the correct size.

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/frequency-win-empirical.eps}
\caption{Empirically measured multiplication reduction for the FIR benchmark. $N$ represents the number of samples for the response of the FIR, and target size represents the target size (approximately $M$). The vertical axis represents the multiplication reduction that is achieved by performing the frequency replacement optimization over the original program. Numbers greater than one represent increased computation and numbers less than one represent a reduction in computation. }
\label{fig:frequency-win-empirical}
\end{figure}


We also performed empirical experiments to measure the multiplication reduction
as a function of both filter size ($N$) and output size ($M$). 
Figure~\ref{fig:frequency-win-empirical} shows empirically measured normalized 
multiplication savings per output. The results match those predicted by the 
above analysis fairly closely.


\subsection{Overall optimization performance}

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/linear-freq-both.eps}
\caption{Results of running the benchmarks with linear replacement, frequency replacement, and both.}
\label{fig:linear-freq-both}
\end{figure}

The FIR scaling investigation is interesting because FIR filtering is a kernel
operation for most DSP applications. To determine the effects of our linear
replacement and frequency replacement optimizations on overall programs, we ran
each benchmark with the linear replacement optimization, the frequency replacement
optimization, and with linear replacement followed by frequency replacement. 
Figure~\ref{fig:linear-freq-both} shows the normalized number of 
multiplications as defined in the last section, required for each 
benchmarks to execute $10000$ steady state iterations for each optimization choice.

For the FIR filter, all of the multiplication reduction comes from the frequency
replacement optimization. As the entire application is comprised of a single
{\tt Filter} calculating a convolution sum, there is nothing to combine.
The target detection program experiences a small decrease in multiplications 
for linear replacement, but it experiences a large boost from frequency replacement.
The main work of the target detector system occurs in the four FIR filters, whose
results can not be combined.

However, FilterBank gets a huge boost from linear replacement because its
parallel analysis and synthesis pipelines can be combined into a single filter.
Our sampling rate converter also benefits greatly from the frequency transformation
due to the fact that it has contains a large FIR filter. The FMRadioApp
benefits from linear replacement because its parallel gain stages are collapsed
into a single filter during linear combination. The number of multiplies in the
Radar app actually increases because our compiler does not take into account the
fact that combined linear structures might actually increase computation.

\section{Results}
We chose to measure the strength of our optimizations in terms of 
floating point instruction reduction. The StreamIt compiler currently
has two code generation backends. The uniprocessor backend generates sequential C code
that can be compiled and linked against a supporting library. 
There is also a backend that generates code for the RAW microprocessor
\cite{waingold97baring, raw-micro}, which features
a grid of processors interconnected via various communication facilities. 
Mapping a StreamIt program on to the RAW architecture is complicated
by issues of communication, load balancing and partitioning\cite{streamit-asplos}. 
Therefore, the effects of our linear analysis optimizations can not
be easily differentiated from differences in placement, routing and fusion that result
from modifying the program's stream graph (as is the case for linear replacement). 
Therefore we chose to use the uniprocessor backend for our measurements.

\subsection{Measurement Methodology}
As always, the appropriate metric to measure performance is not totally clear. 
Running time is complicated by the multitasking environment offered by 
modern operating systems. Also, given that the uniprocessor backend for
the StreamIt compiler is meant for prototyping, the supporting 
library is anything but optimized. Therefore, measuring running time is
probably not an appropriate metric.

The fundamental metric of processing performance is amount of computation, and since
our optimizations are both aimed at reducing the amount of computation we will focus 
on that reduction in our results section. Most of the applications that are and will
be written in StreamIt process floating point data with floating point instructions (FLOPs), 
and so reducing their number is good for overall performance. 
Therefore, we chose the reduction in FLOPs as our measurement metric executed.

Our measurement platform was a Dual Intel 2.2 GHz P4 Xenon processor system 
running Linux. We compiled the benchmark programs using StreamIt's uniprocessor
and compiled the resulting C code with {\tt gcc}, with {\tt -O2} optimization.

Obviously statically counting the number of FLOPs in a program is not helpful. We 
need to measure the number of floating point instructions that are executed at runtime.
To do measure FLOPs dynamically, we utilized the DynamoRIO\cite{rio-webpage}
runtime introspection and optimization infrastructure. Using a simple DynamoRIO application 
we instrumented each benchmark program at runtime and counted the number of FLOPs executed.


We define three instruction types of interest for the Intel x86 instruction set:
\begin{itemize}
\item[flops] Any opcode whose name that begins with {\tt f} in the x86 instruction set.
\item[fadds] Any of ({\tt fadd faddp fiaddp fsub fsubp fisubp fsubr fsubrp fisubr}).
\item[fadds] Any of ({\tt fmul fmulp fimulp fdiv fdivp fidivp fdivr fdivrp fidivr}).
\end{itemize}

There are no standard benchmark written for StreamIt, so we had to assemble
a set of programs which perform computations that are likely to be representative
real world applications. We settled on a set of six, which we describe below.

\begin{enumerate}
\item FilterBank: Implements a multi-rate signal decomposition processing block which is common in communications and image processing.
\item FIR: A single 100 point FIR filter which implements a low pass filter with cutoff frequency $\omega_c=\frac{\pi}{3}$
\item FMRadio: Implements an FM demodulator in software.
\item RateConverter: Converts a sampling rate $f_{s1}=\frac{1}{T}$ to $f_{s2}=\frac{3}{2T}$.
\item TargetDetect: Four matched filters perform threshold target detection in parallel.
\item Radar: radar frontend, beamformer and target detection.
\end{enumerate}


\subsection{Linear Replacement}

\begin{figure}
x\center
\epsfxsize=3.0in
\epsfbox{images/combination-graph.eps}
\caption{Performance gains realized by replacing structures with direct linear forms.}
\label{fig:combination-graph}
\end{figure}


\subsection{Frequency Replacement}
\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/freq-scaling.eps}
\caption{Results of scaling the target FIR size versus number of multiplies for the FIR kernel.}
\label{fig:freq-scaling}
\end{figure}

As mentioned above, even though we are converting an $O(N^2)$ implementation into an
$O(N lg N)$ algorithm, the hidden constant hidden $O(N lg N)$ is non trivial. In
Figure~\ref{fig:freq-scaling} we show the results of choosing different target sizes
for the frequency implementation. The X axis shows the various sizes chosen, and 
the Y axis shows the number of multiplies required per output compared to the normal
implementation. A number less than one means that fewer multiplies were required after
our transformation, and a number more than one means that more multiplies were required.

(discuss specific results)

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/linear-freq-both.eps}
\caption{Results of running the benchmarks with linear replacement, frequency replacement, and both.}
\label{fig:linear-freq-both}
\end{figure}

We can also hope to get performance gains by combining our two optimizations. 
If the compiler can figure out that several filters are all doing linear operations
and combine them together we already probably win. If, however, we can then tranform
the overall representation into the frequency domain, we can win big. 
Figure~\ref{fig:linear-freq-both} shows the normalized number of multiplications
required per output when linear replacement is applied, when the frequency transformation 
is applied, and when both are applied, frequency tranformation following linear replacement.

(discuss specific results)
\section{Introduction}
As more and more parts of modern life use digital computation, everything from cell phones, GPS systems
and satellite radios, require ever more complicated processing of digital signals. 
Each successive generation of applications requires ever more sophisticated algorithms mapped 
on to ever more specialized digital signal processors (DSP). As 
embedded devices have severe performance requirements placed on them,
the mapping of algorithm to architecture is typically done by hand at great cost and great expense.

Upward of fifty percent of the code that runs the DSP(s) in a modern cell phone is coded in assembly
with the rest written in C. Hand optimized assembly code typically makes the best use of the 
available resources such as power, specialized coprocessors, and specialized instructions.
The problem with assembly code is that the same algorithm must be mapped time and time again 
whenever a new chip comes out. The life cycle of a typical DSP is much shorter than the life
cycle of a general purpose microprocessor -- each new generation is separated by months rather
than years.
 
Therefore frequently reimplementing algorithms by hand is a costly arduous process that 
increases cost and slows the pace of advances. Engineers must spend time working out details rather 
than focusing on solving harder problems. Compilers were invented forty years ago 
exactly to let engineers focus on the problem at hand rather than spend time with 
machine specific details. Compilers for DSP architectures have a difficult job, and are not
very good at mapping a program written in a general purpose language like C into the specialized 
instructions provided by DSPs. Many of the instructions provided by a DSP are targeted 
for a very specific application (like FIR filtering), but most general purpose languages have
no way to describe higher level behavior other than functionally. If you don't express
your algorithm in the same way that the compiler expects to encounter it, the resulting
program will not take best advantage of the available DSP resources.

We are attempting to solve this problem by introducing a new domain specific language which
supports imperative C like code to describe computation. By imposing structure and
explicitly identifying the input and the output of different program sub components
we can run an analysis that determine if a program is performing a common DSP task.  
We can then use this information to take advantage of special purpose DSP hardware
or we can even apply standard signal processing algorithm optimizations to 
We can then leverage the existing work on DSP algorithm optimization to perform compiler transformation
at a fairly sophisticated level. Our system lets programmers describe the
computation to be performed at an appropriate level and the compiler takes care of 

\subsection{Motivating Example}
\begin{figure}
\center
\epsfxsize=2.0in
\epsfbox{images/motivating-example.eps}

\begin{verbatim}
float data[N]; /* input data buffer */
float buffer[N]; /* inter-filter buffer */

/* initialize inter-filter buffer */
for (i=0; i<N; i++) {
  /* filter starting at index i of input data, wrap around */
  buffer[i] = filter(weights1, data, i, N);
  data[i] = get_next_input();
}

i = 0;
while(true) {
  push_output(filter(weights2, buffer, i, N));
  /* get next data item */
  data[i] = get_next_input();
  /* generate the next element in the inter filter buffer */
  buffer[i] = filter(weights1, data, i, N);
  /* update current start of buffer */
  i = (i+1)%N
}
\end{verbatim}
\caption{FIR filtering with back to back filters in C. Note the use of circular buffers.}
\label{fig:motivating-example}
\end{figure}

As an example of the types of program transformation that our optimization allows,
consider a sequence of finite impulse response (FIR) filters as shown in 
Figure~\ref{fig:motivating-example}. The imperative C style code that implements
this simple DSP application is also shown. The program largely defies many
standard compiler analysis and optimization techniques because of its use of circular
buffers and the muddled relationship between {\tt data}, {\tt buffer} and the output.

\begin{figure}
\begin{verbatim}
float->float pipeline TwoPipe {
  add FIRFilter(weights1);
  add FIRFilter(weights2);
}

float->float filter FIRFilter(float[N] weights) {
  work push 1 pop 1 peek N {
    float sum = 0;
    for (int i=0; i<N; i++) {
      sum += weights[i] * peek(i);
    }
    push(sum);
    pop();
}
\end{verbatim}
\caption{StreamIt program to implement the same processing as the program in Figure~\ref{fig:motivating-example}}
\label{fig:example-streamit}
\end{figure}


Figure~\ref{fig:example-streamit} shows the same filtering process implemented in 
StreamIt. The StreamIt program is better because it uses explicit input/output channels,
lets the compiler worry about buffer management and shows the structure of the original
block diagram. 


\begin{figure}
\begin{verbatim}
float->float filter LinearTwoPipe() {
  work push 1 pop 1 peek N {
    float sum = 0;
    for (int i=0; i<N; i++) {
      sum += combined_weights[i]*peek(i);
      }
    push(sum);
    pop();
  }
}
\end{verbatim}
\caption{Program after combination in psuedo-StreamIt.}
\label{fig:example-combine}
\end{figure}

Our data analysis provides a complete relationship between input and output for
each filter, and furthermore can combine the actions of the two filters as shown
in Figure~\ref{fig:example-combine}. The new combined filter's {\tt combined\_weights}
array contains elements such that the overall output is the same.

\begin{figure}
\begin{verbatim}
float->float filter FreqTwoPipe() {
  complex[N] H;
  init {
    H = FFT(combined_weights);
  }
  work push L pop L peek N+L {
    float[N] X = FFT(peek(0..N+L-1)); /* input FFT */
    float[N] Y =  X .* H; /* element wise mult */
    float[N] y = IFFT(Y); /* inverse FFT */
    push(y[0..L-1]); /* push first L elts of y */
  }
}
\end{verbatim}
\caption{Program after using the FFT to implement the filter in psuedo-StreamIt.}
\label{fig:example-frequency}
\end{figure}

Out compiler can actually go one step farther and apply a well known 
optimization to calculate the output values using a frequency transformation
as is outlined in psuedo code in Figure~\ref{fig:example-frequency}.




\subsection{StreamIt}

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/general-picture-filter.eps}
\caption{Graphical illustration of $e_{F}$, $o_{F}$ and $u_{F}$}
\label{fig:overview-filter}
\end{figure}


The StreamIt\cite{streamitcc, streamit-asplos, gordon-thesis} language
aims to provide a language and compiler for streaming applications. Streaming applications 
are characterized by data streaming in and out of the application. Each data element (both
input and output) is in the system for only a small amount of time as opposed to scientific
applications where the data set is typically used extensively over the execution time.

StreamIt programs are composed of processing blocks called {\tt filters} which
contain an input tape from which they can read values and an output tape to which
they can write. Each {\tt filter} contains a {\tt work} function which describes 
a steady state computation that consumes input and produces output.
{\tt filters } can examine data items  on the input tape without consuming them 
via {\tt peek} expressions. {\tt pop} expressions consume data from the input
tape. A {\tt filter} calls {\tt push} to add values to the output tape.
{\tt filters} can contain stateful fields that persist between calls to {\tt work}. 
The {\tt work} function is C-like imperative code, 
which can access {\tt filter} state, call external routines and produce and consume data. 
There are few restrictions on a {\tt work} function other than the requirement that
it consume input and produce output at the stated rates.

All {\tt filters} in StreamIt declare the number of elements they
will {\tt peek} at, the number of elements they will {\tt pop} and the number
of elements that they will {\tt push}. A {\tt Filter} $F$ can examine up to $e_F$ 
items from its input tape, consumes exactly $o_F$ items and produces exactly
$u_F$ items. Currently StreamIt requires that each filter has declared $e_F$, $o_F$ 
and $u_F$ that are statically determinable at compile time. 
Figure~\ref{fig:overview-filter} shows how $e_F$, $o_F$ and $u_F$ are related.

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/streamit-structures.eps}
\caption{StreamIt structures: {\tt pipeline}, {\tt splitjoin}, and {\tt feedbackloop}.}
\label{fig:structures}
\end{figure}

{\tt filters} in StreamIt are composed hierarchically using predefined structures to form
a program. 

\begin{enumerate}
\item {\tt pipelines} represent the serial computation of one filter after another.
\item {\tt splitjoins} represent explicitly parallel computation. 
\item {\tt feedbackloops} allow cycles to be introduced into the stream graph. 
\end{enumerate}

{\tt filters}, {\tt pipelines}, {\tt splitjoins} and {\tt feedbackloops} 
are all {\tt streams} and each {\tt stream} can be used as a subcomponent in 
a structure. Figure~\ref{fig:structures} illustrates the three structures 
provided as primitives in StreamIt.
StreamIt programs can therefore be represented as a connected graph of filters 
which we will refer to as the stream graph. It is also important to note
{\tt streams} have exactly one input tape and one exactly one output tape.

Most real world programs can be fit into StreamIt's structured stream model, 
though the fit sometimes requires extra manipulation. We believe
that benefits of structure to both the programmer and the compiler outweigh the
costs of imposing structure on the programmer.

\subsection{Matrices and DSP}
We take advantage of StreamIt's explicit input and output tapes and
our knowledge that a large class of StreamIt programs will be performing
standard digital signal processing (DSP) operations to generate useful
optimizations.

There is an entire research area in Electrical Engineering devoted to DSP. The
theory and the implementation of systems to process digital signals is well developed (see
an introductory text such as\cite{oppenheim-discrete} or \cite{lyons-understanding}). 
There are a few fundamental primitives used to describe most DSP systems, and the output of 
most of these primitives can be expressed as a linear combination of their inputs. Examples are
finite impulse response (FIR) filters, compressors, expanders and signal processing transforms
such as the discrete Fourier transform (DFT) and discrete cosine transformation (DCT).

Electrical engineers who concentrate on DSP applications spend a large percentage of their 
time designing an appropriate implementation given a particular design. Choosing
the appropriate implementation structure is a highly non trivial task, and sometimes determining the 
the ``right'' choice is often more of an art than a science. There are many systems that allow a
designer to explore design choices such as Matlab\cite{matlab} which is used extensively in
both academia and industry.  There are also research projects such as \cite{covell-ade} 
and those described in \cite{oppenheim-symbolic} aimed at allowing a DSP designer to explore
various implementation choices.(XXXXXXXXXXXXx -- Are there other things we should reference here?) 

Given that a product called Matlab (as in  MATrix LAB) is used extensively
in DSP applications, it is probably not surprising that matrices often provide 
a convenient way of working with digital data and for describing digital filters. 
If a {\tt work} function is doing matrix computation, by recognizing this fact
we can take advantage of the huge body of existing knowledge.

% this thing used to be about optimizations, now it is all about ``Translation to Frequency Domain''

\section{Translation to Frequency Domain}
Our linear analysis framework provides a compile time formulation of the 
computation that a linear {\tt stream} is performing and we can use this information 
to exploit well known domain specific optimizing transformations. 
We have implemented one such optimization which is implementing
convolution using a translation to the frequency domain.

Calculating a convolution sum is a fundamental operation in discrete time signal processing 
because it defines how to compute the output of a linear time invariant 
(LTI) system from the inputs.

The convolution sum $y[n]=x[n]*h[n]$ is defined as $y[n]=\sum_{k=-\infty}^{\infty}x[k]h[n-k]$. 
If $h[n]$ for $n\in[0..L-1]$ are compile time known constants, 
a frequency transformation using the DFT can be employed to quickly calculate $y[n]$. 
The transformation from convolution sum into frequency multiplication is currently
done explicity by the programmer because it is difficult for traditional compilers 
to determine that a convolution sum is being computed and which program variables
correspond to $x[n]$, $h[n]$ and $y[n]$.

However, for StreamIt {\tt streams} we know that the input ($x[n]$) and output ($y[n]$)
correspond exactly to our input and output tapes. Furthermore, the values $h[n]$ 
are exactly in the columns of $A$. A filter $F$ that is calculating a convolution 
will have $o_F=1$.

Fewer calculations are often required to transform
the input signal to the frequency domain, do a multiplication, and then convert back 
to time than it does to do the convolution directly. This seeming roundabout calculation
is feasible because a class of fast algorithms known as the FFT are known that convert
to frequency and back again. For a thorough treatment of the theory of discrete time 
signal processing, the DFT and FFT, see \cite{oppenheim-discrete}.

% put something here about how you calculate a convolution withDFT
% then talk about stupid implementation, then smaprt implementation.

We define an filter computing a convolution sum as a FIR filter. An FIR filter $F$ has
$e_F=M$, $o_F=1$ and $u_F=1$. To transform $F$ such that it uses and consumes $N+M-1$ input
elements to produce $N+M-1$ outputs per {\tt work} function execution. We use the 
following notation in the rest of this section to remain consistent with DSP terminology.
$h[n]$ is the filters ``impulse response'' and consists of the values in the linear 
representation matrix. $x[n]$ is the next $N+M-1$ block of the input that the filter
will process. $y[n]$ is is the $N+M-1$ values the filter produces.

Our compiler computes the complex values of $H[k]=H(e^{j\omega})|_{\omega=\frac{2{\pi}k}{L}}$, 
the DFT of $h[n]$, at compile time. The filter is transformed 
so that it  calculates $X[k]=X(e^{j\omega})|_{\omega=\frac{2{\pi}k}{L}}$, the DFT 
of $x[n]$. Then it calculates $Y[k]=X[k]H[k]$, the DFT of $h[n]*x[n]$.
Then the filter converts $Y[k]$ into $y[n]$ using the inverse DFT. Finally, 
the appropriate values from $y[n]$ are pushed on to the output tape. The
calculations of the DFT are implemented using the the well-known 
``fast Fourier transform'' (FFT) algorithm.

\begin{figure}
\center
\epsfxsize=3.0in
\epsfbox{images/frequency-example.eps}
\caption{Example of edge case in frequency results.}
\label{fig:frequency-example}
\end{figure}

As always, the devil is in the details. We have not mentioned above either 
the size of the DFT($L$), how to deal with initial conditions, or which 
values of $y[n]$ to push on to the output tape. 
Without going into detail, we use a simple overlap and add\cite{oppenheim-discrete} 
method to calculate the values of $y[n]$ for each iteration. To do so 
we need to introduce state into our filters. If the filters did not have state
we would have to throw out partial values each execution of the {\tt work} function
which makes our technique much less effective. Figure~\ref{fig:frequency-example} shows
the basic idea of what is going on.



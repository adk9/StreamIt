\begin{figure}
\begin{minipage}{3.2in}
\vspace{18pt}
\centering
\psfig{figure=duplicate-fission.eps,width=3.6in}
\vspace{-12pt}
\caption{\protect\small Fission of filter that peeks.
\protect\label{fig:fission-peek}}
\end{minipage}
\begin{minipage}{3.2in}
\centering
\psfig{figure=duplicate-fission-2.eps,width=3.6in}
\vspace{-12pt}
\caption{\protect\small Fission of filter that does not peek.
\protect\label{fig:fission-nopeek}}
\end{minipage}
\\
\begin{minipage}{6.5in}
\centering
\psfig{figure=fuse-pipeline.eps,width=6.5in}
\vspace{-18pt}
\caption{\protect\small Fusion of a Pipeline into a two-stage filter.
\protect\label{fig:fuse-pipe}}
\vspace{-6pt}
\end{minipage}
\\
\begin{minipage}{2.75in}
\centering
\vspace{48pt}
\centering
\psfig{figure=splitjoin-split.eps,width=3.25in}
\vspace{-12pt}
\caption{\protect\small Breaking a SplitJoin into hierarchical units.
\protect\label{fig:splitjoin-split}}
\vspace{-6pt}
\end{minipage}
\begin{minipage}{3.75in}
\vspace{-6pt}
\centering
\psfig{figure=fuse-splitjoin.eps,width=3.75in}
\vspace{-12pt}
\caption{\protect\small Fusion of a SplitJoin construct.
\protect\label{fig:fuse-splitjoin}}
\vspace{-6pt}
\end{minipage}
\end{figure}

\begin{figure}
\begin{minipage}{3in}
\vspace{-6pt}
\centering
\psfig{figure=sync-removal.eps,width=3in}
\vspace{-18pt}
\caption{\protect\small Synchronization removal.
\protect\label{fig:sync-removal}}
\vspace{-6pt}
\end{minipage}
\begin{minipage}{3.5in}
\psfig{figure=filter-hoisting.eps,width=3.5in}
\vspace{-12pt}
\caption{\protect\small Filter hoisting.
\protect\label{fig:filter-hoisting}}
\vspace{-6pt}
\end{minipage}
\end{figure}

\section{Partitioning}
\label{sec:partition}

StreamIt provides the Filter construct as the basic abstract unit of
autonomous stream computation.  The programmer should decide the
boundaries of each Filter according to what is most natural for the
algorithm under consideration.  While one could envision each Filter
running on a separate machine in a parallel system, StreamIt hides the
granularity of the target machine from the programmer.  Thus, it is
the responsibility of the compiler to adapt the granularity of the
stream graph for efficient execution on a particular architecture.

We use the word {\it partitioning} to refer to the process of dividing
a stream program into a set of balanced computation units.  Given a
number $N$, which represents the maximum number of computation units
that can be supported, the partitioning stage transforms a stream
graph into a set of no more than $N$ filters, each of which performs
approximately the same amount of work during the execution of the
program.  Following this stage, each filter can be run on a separate
processor to obtain a load-balanced executable.

Load balancing is particularly important in the streaming domain,
since the throughput of a stream graph is equal to the {\it minimum}
throughput of each of its stages.  This is in contrast to scientific
programs, which often contain a number of stages which process a given
data set; the running time is the {\it sum} of the running times of
the phases, such that a high-performance, parallel phase can partially
compensate for an inefficient phase.  In mathematical terms, Amdahl's
Law captures the maximum realizable speedup for scientific
applications, but for streaming programs, the maximum improvement in
throughput is given by the following expression:
\begin{align*}
\mbox{\it Maximum speedup}(w, c) = \frac{\sum_{i=1}^m{c_i \cdot w_i}}{MAX_i(c_i \cdot w_i)}
\end{align*}
where $w_1 \dots w_m$ denote the amount of work in each of the $m$
partitions of a program, and $c_i$ denotes the multiplicity of work
segment $i$ in the steady-state schedule.  Thus, if we double the load
of the heaviest node, then the performance will suffer by a factor of
two.  The impact of load balancing on performance places particular
value on the partitioning phase of a stream compiler.
% This can be posed in
% mathematical terms by appealing to Amdahl's Law, which expresses the
% maximum speedup that can be achieved on $N$ processors when there are
% $S_1 \dots S_x$ units of sequential work and $P_1 \dots P_y$ units of
% parallel work:
% \begin{align*}
% \mbox{\it Maximum speedup}(S, P, N) = \frac{\sum_{i=1}^x{S_i}+\sum_{i=1}^y{P_i}}{\sum_{i=1}^x{S_i}+\frac{\sum_{i=1}^y{P_i}}{N}}
% \end{align*}
% However, in a stream program, the measure of performance is throughput
% rather than running time.  Using $w_1 \dots w_m$ to denote the amount
% of work in each of the $m$ partitions of a program, and denoting the
% multiplicity of work segment $i$ in the steady-state schedule by
% $c_i$, we have that:

\subsection{Overview}

\begin{figure}[t]
\vspace{-6pt}
\begin{minipage}{3.1in}
\psfig{figure=orig-blood.eps,width=1.7in}
\vspace{-12pt}
\caption{\protect\small Blocking diagram for the naive partitioning of
 FM Radio.
\protect\label{fig:fmblood1}}
\end{minipage}
\hspace{0.3in}
\vspace{-12pt}
\begin{minipage}{3.1in}
\psfig{figure=adjust-2-blood.eps,width=3in}
\caption{\protect\small Blocking diagram for the optimized
partitioning of FM Radio.
\protect\label{fig:fmblood2}}
\end{minipage}
\vspace{-6pt}
\end{figure}

Our partitioner employs a set of fusion, fission, and reordering
transformations to incrementally adjust the stream graph to the
desired granularity.  To achieve load balancing, the compiler
estimates the number of instructions that are executed by each filter
in one steady-state cycle of the entire program; then, computationally
intensive filters can be split, and less demanding filters can be
fused.  Currently, the decision of which transformations to apply is
done by hand, but the transformations themselves are fully automated.

We return to our software radio example to illustrate the partitioning
process.  Figure~\ref{fig:fmblood1} illustrates a blocking diagram for
the original partitioning of the radio (which appears in
Figure~\ref{fig:?1}).  The dark bands indicate where a processor is
waiting to send or receive an item, while the light areas indicate
periods of useful work.  With the filters partitioned in the original
configuration, most of the processors spend their time waiting for the
input from the first LowPassFilter.

Figure~\ref{fig:?2} illustrates a sequence of transformations that
improve the load balancing for the radio, resulting in the blocking
diagram shown in Figure~\ref{fig:fmblood2}.  \todo{Describe the
transformations} In the following sections, we describe these
transformations in more detail.

% note that sometimes you have to fuse and then later fizz, if you
% want partial multiplication of a given work function

\subsection{Fusion Transformations}

Filter fusion is a transformation whereby several adjacent filters are
combined into one.  Fusion can be applied to decrease the granularity
of a stream graph so that an application will fit on a given target,
or to improve load balancing by merging small filters so that there is
space for larger filters to be split.  Analogous to loop fusion in the
scientific domain, filter fusion can enable other optimizations by
merging the control flow graphs of adjacent nodes, thereby shortening
the live ranges of variables and allowing independent instructions to
be reordered.

\subsection{Vertical Fusion}

Vertical fusion describes the combination of sequential, pipelined
filters into a single unit.  We have developed a vertical fusion
algorithm for StreamIt filters that we describe below.  For the more
limited domain of filters that do not contain peek statements,
Proebsting and Watterson \cite{pro96} present a filter fusion
algorithm that interleaves the control flow graphs of adjacent nodes.
However, they assume that nodes communicate via synchronous {\tt get}
and {\tt put} operations, such that StreamIt's asynchronous peek
operations and implicit buffer management fall outside the scope of
their model.

Our algorithm relies on the static I/O rates of each filter to
calculate a legal execution ordering for the filters being fused.
Then, the fused filter simulates the execution of this schedule,
inlining the code from each of the original filters and using local
variables for buffering.  In our current implementation, the scheduler
computes only the multiplicity of each component filter in relation to
the fused filter; then, the fused code is a sequence of loops that
each execute a component filter for the appropriate multiplicity,
buffering its results in a local array.  If the multiplicity is small,
then the loop can be unrolled and all array references can be replaced
with scalar variables to facilitate optimization.

A subtlety of our algorithm is that the fused filter differs from the
originals in that it has two distinct execution phases: one for
initialization, and one for steady-state execution (see
Figure~\ref{fig:fuse-pipe}).  If any of the component filters peek at
elements that they do not consume, then a separate initialization
schedule is required to fill all the ``peek buffers'' in the pipeline.
During this initialization, the pipeline as a whole will consume some
input, but will not produce any output.  Then, during the steady state
schedule, the sizes of the buffers are preserved, and the pipeline
both produces and consumes items.  Thus, when there is peeking in the
stream, there will be different I/O rates for the initialization and
steady-state phases, and the fused filter will be a {\it two stage
filter}: it executes one work function on its first invocation, and a
separate work function on all subsequent invocations.  Though these
work functions may have different I/O rates, each rate is constant and
known at compile time.

\subsection{Horizontal Fusion}

We refer to the combination of the parallel streams in a SplitJoin
construct as ``horizontal fusion''.  Our horizontal fusion algorithm
inputs a SplitJoin where each component is a single filter, and
outputs a Pipeline of three filters: one to emulate the splitter, one
to simulate the execution of the parallel filters, and one to emulate
the joiner.  The splitters and joiners need to be emulated in case
they are RoundRobin's that perform some reordering of the data items
with respect to the component streams.  The fusion of the parallel
components is similar to that of vertical fusion--a sequential
steady-state schedule is calculated, and the component work functions
are inlined and executed within loops.  However, horizontal fusion
requires no buffering of internal items, as the parallel streams do
not communicate with each other.  Also, for Duplicate splitters, the
{\tt pop} expressions in component filters need to be converted to
{\tt peek} expressions so that items are not consumed before
subsequent filters can read them.

\subsection{Fission Transformations}

Filter fission is the analog of parallelization in the streaming
domain.  It can be applied to increase the granularity of a stream
graph to utilize unused processor resources, or to break up a
computationally intensive node for improved load balancing.  

There are many types of fission transformations.  We have implemented
a data-parallel transformation for stateless filters that places a
duplicate of the filter on each path of an $n$-way SplitJoin (see
Figures~\ref{fig:duplicate-fission}-\ref{fig:duplicate-fission2}).  By
``stateless'' we mean that the filter contains no fields that are
written on one invocation of {\tt work} and read on later
invocations--let us consider such a filter $F$ with I/O rates of
$peek$, $pop$, and $push$.  Our transformation produces a SplitJoin
that has a set of two-stage filters as its components.  The $i$'th
component has a steady-state work function that is exactly the same as
in $F$, and an initialization work function that simply pops
$(i-1)*pop$ items from the input stream (to account for the
consumption of previous filters).  If $peek=pop$, the splitter is a
RoundRobin that routes $pop$ elements to each component stream.
However, if $peek>pop$, then the splitter is a Duplicate, and each
stream contains a decimator to consume items that are unused by the
component filter.  In either case, the joiner is a RoundRobin that has
a weight of $push$ for each input.

Instead of duplicating the entire contents of a filter, some filters
can be split into a pipeline, with each stage performing some part of
the work function.  In addition to the original input data, these
pipelined stages might need to communicate intermediate results from
within {\tt work}, as well as fields within the filter.  This scheme
could apply to filters with state if all modifications to the state
appear at the top of the pipeline (they could be sent over the data
channels), or if changes are infrequent (they could be sent via
StreamIt's messaging system.)  Also, some state can be identified as
induction variables, in which case their values can be reconstructed
from the {\tt work} function instead of stored as fields.
% no space to talk about stateless feedback loop fission

\subsection{Reordering Transformations}

There are a multitude of ways to reorder the elements of a stream
graph so as to facilitate fission and fusion transformations.  For
instance, identical stateless filters can be pushed through a splitter
or joiner node if the weights are adjusted accordingly
(Figure~\ref{fig:filter-hoisting}); a SplitJoin construct can be
divided into a hierarchical set of SplitJoins to enable a finer
granularity of fusion (Figure~\ref{fig:splitjoin-split}); and
neighboring splitters and joiners with matching weights can be
eliminated (Figure~\ref{fig:sync-removal}).


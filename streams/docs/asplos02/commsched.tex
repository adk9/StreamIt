\section{Communication Scheduler}
\label{sec:communic}

With the nodes of the stream graph assigned to computation nodes of
the target, the next phase of the compiler must map the communication
explicit in the stream graph to the interconnect of the target.  This
is the task of the communication scheduler.  The communication
scheduler maps the infinite FIFO abstraction of the stream channels to
the limited resources of the target.  The communication scheduler must
avoid deadlock and starvation while trying to utilize the parallelism
explicit in the stream graph.

The exact implementation of the communication scheduler is tied to the
communication model of the target.  The simplest mapping would occur
for targets implementing an end-to-end, infinite FIFO abstraction, the
scheduler needs only to decide to whom to send an item and from whom
to receive an item.  Information easily calculated from the weights of
the Splitters and Joiners.  As the communication model becomes more
constrained, the communication scheduler becomes more complex,
requiring analysis of the stream graph. For targets implementing a
finite, blocking nearest-neighbor communication model, the exact
ordering of tile execution must be specified. 

Due to the static nature of StreamIt, the compiler can statically
orchestrate the communication resources.  We can create an
initialization schedule and a steady-state schedule that fully
describe the execution of the stream graph.  The schedules can give us
an order for execution of the graph if necessary.  We can generate
ordering to minimize buffer length, maximize parallelism, or minimize
latency.  

%Thus, we can create a communication scheduler of arbitrary
%detail.  If the architecture must statically orchestrate all aspects
%of communication, the StreamIt language provides this facility.

Deadlock must be carefully avoided in the communication
scheduler. Each architecture requires a different deadlock avoidance
mechanism and we will not go into a detailed explanation of deadlock
here.  In general, deadlock occurs when there is a circular dependence
on resources.  A circular dependence can surface in the stream graph
or in the routing pattern of the layout.  If the architecture does not
provide sufficient buffering, the scheduler must serialize all
potentially deadlocking dependencies.

%Two StreamIt language constructs that can lead to deadlock are
%FeedbackLoops and Joiners. Figure ?? describes the potential for
%deadlock in a FeedbackLoop.  One potential solution is to forbid
%filters of the FeedbackLoop to interleave sends and receives.  This
%has the effect of serializing the FeedbackLoop. In figure ?? we
%descibe the potential for deadlock introduced by Joiner nodes.  A
%solution to this problem is described below.

\subsection{Raw's Communication Scheduler}
\label{sec:rawcommunic}

The communication scheduling phase of the StreamIt Compiler maps
StreamIt's channel abstraction to Raw's static network.  As mentioned
in Section \ref{sec:raw}, Raw's static network provides optimized, nearest
neighbor communication.  Tiles communicate using buffered, blocking
sends and receives.  It is the compiler's responsibility to statically
orchestrate the explicit communication of the stream graph while
preventing deadlock.

To statically orchestrate the communication of the stream graph, the
communication scheduler simulates the firing of nodes in the stream
graph, recording the communication as it simulates.  The simulation
does not model the code of each Filter, instead it assumes that each
Filter fires instantaneously.  The flow-control of the static network
allows this relaxation.  Instead the simulator operates on the
granularity of a data item.  Modeling the path each data item follows.

We simulate the graph for both an initialization schedule and a steady
state schedule, both are described in section ??.  A push model
schedule is used for both phases.  We define a push model schedule as
a schedule that advances computation on the furthest downstream node
in the stream graph at each step.  The push model schedule allows the
implementationto disregard the FIFO buffers that connect each neighboring
node in the stream graph.  This is because data items will not be
accumulating at the source, dest, or intermediate nodes.  
Each destination will consume the data
item as it is produced (modulo the latency of routing).

To assure deadlock free execution of Joiner nodes, we must allow the
Joiner nodes to receive data in the firing order of its upstream
Filters (figure ??). So, the Joiner must buffer data until it can fire
in the order specified by its incoming weights.  First, remember that
we collapse all neighboring Joiners into a single Joiner node.
We create an internal buffer for each
incoming channel of the collapsed Joiner.  During execution of the
simulation, we record the order of receives to and send from these
internal buffers.

To create this Joiner buffer schedule, the simulator must keep track
which internal buffer can send data.  The order can be calculated from
the weights of the joiner (as each buffer corresponds to an upstream
Filter).  When the current buffer in this order has more than one item
in it, the Joiner can fire.  The simulator can then determines the
next internal buffer to send data.  To faciliate code generation
(Section \ref{sec:codegen}), the maximum buffer size of each internal
buffer is recorded.

Our current implemenation of the communication scheduler is overly
cautious in its deadlock avoidance.  All Feedbackloops are serialized
by the communication scheduler to prevent deadlock.  More precisely, 
the loop and body streams of the FeedBackLoop cannot execute in
parallel.  Crossed routes in the layout of the graph are serialized as
well, forcing each path to wait its turn at the contention point.

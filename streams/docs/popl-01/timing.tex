\section{Semantics of Time}
\label{sec:time}
In this section we develop a more formal semantics for the message
delivery guarantees described above.  The timing model in StreaMIT is
unique in that all time is relative to {\it information
wavefronts}--that is, two independent filters can describe a common
time only in terms of when the {\it effects} of one filter's execution
are seen by the other.  Thus, although each filter's {\tt work}
function is invoked asynchronously without any notion of global time,
two invocations of a work function occur at the same
``information-relative time'' if they operate on the same information
wavefront.

To define this notion more precisely, we present transfer functions
that describe the flow of information across filters and streams.
Using these transfer functions, we translate message delivery
constraints into a set of constraints on the execution schedule of the
stream graph.  Finally, we use these scheduling constraints to
formulate an operational semantics for messaging and latency in
StreaMIT.

\subsection{Information Flow}

The concept of information flow is central to the streaming domain.
When an item enters a stream, it carries with it some new information.
As execution progresses, this information cascades through the stream,
effecting the state of filters and the values of new data items which
are produced.  We refer to an ``information wavefront'' as the
sequence of filter executions that first sees the effects of a given
input item.  This wavefront is well-defined even in the presence of
rate-changing filters that peek or pop a different number of items
than they push.

\begin{figure}
\centering
\psfig{figure=Tapes.eps,width=3.2in}
\caption{The behavior of the tapes in a filter that pops two items
from the input channel, peeks at the next three, and pushes two
elements to the output channel. The tape of the input channel before
an invocation is drawn on the left. The state of the input channel
tape, the output channel tape, and the filter during execution is
shown in the middle. The state of the output channel tape after
completion of the filter's execution is given on the right.}
\label{fig:tapes}
\end{figure}

To formalize the wavefront, we introduce some new representations for
the state of the stream graph.  Consider that in place of each data
channel there is an infinite ``tape'' which contains the history of
values that have been pushed onto the channel (see Figure
\ref{fig:tapes}).  Now consider the following functions:
\begin{itemize}
\item Given that there are $x$ items on tape $a$, the maximum number
of items that can appear on tape $b$ is $\ma{a}{b}(x)$.

\item Given that there are $x$ items on tape $b$, the minimum number
of items that must appear on tape $a$ is $\mi{a}{b}(x)$.
\end{itemize}
Note that these functions are only defined over pairs of tapes $(a,
b)$ where $a$ is ``upstream'' of $b$--that is, where there is a
directed path in the stream graph from the filter following $a$ to the
filter preceding $b$.

The $max$ and $min$ functions are related to the information wavefront
in the following sense.  The item at position $y = \mi{a}{b}(x)$ of
tape $a$ is the latest item on tape $a$ to {\it affect} the item at
position $x$ of tape $b$.  This is because item $x$ on tape $b$ can be
produced if and only if tape $a$ contains at least $y$ items.  Note
that this effect might be via a control dependence rather than a data
dependence--for instance, if item $y$ needed to pass through a
round-robin joiner before some data from another stream could be
routed to tape $b$.

We now turn to deriving expressions for $\ma{a}{b}$ and $\mi{a}{b}$ as
a step towards formalizing the semantics of messaging and latency in
StreaMIT.

\subsubsection{Filters}

Consider a filter $A$ that peeks $peek_A$, pops $pop_A$, and pushes
$push_A$ data items on every execution step.  Further, let us denote
the input and output tapes of $A$ by $I_A$ and $O_A$, respectively.
We now turn our attention to finding $\ma{I_A}{O_A}$ and
$\mi{I_A}{O_A}$, describing the transfer of information across the
filter $A$.

To derive $\ma{I_A}{O_A}(x)$, observe that the filter can execute so
long as it does not peek beyond the $x$'th item on the input tape,
$I_A$.  After the $n$'th execution, it has popped $n$ items, peeked up
to $n + (peek_A - pop_A)$, and popped $2 * n$ items.  Thus, it can
execute $n = \lfloor(x - (peek_A - pop_A)) / pop_A)\rfloor$ times, leaving
the following expression for $\ma{I_A}{O_A}(x)$

\[
\begin{array}{l}
\ma{I_A}{O_A}(x)  \\ 
\makebox[.1in]{ } = \left\{
\begin{array}{ccl}
push_A*\left\lfloor\frac{x-(peek_A-pop_A)}{pop_A}\right\rfloor & if & x \ge (peek_A-pop_A) \\
 & \\
0 & if & x < (peek_A-pop_A) \\
\end{array} \right.
\end{array}
\]

\subsubsection{Pipelines}

Let us now derive expressions for $min$ and $max$ in the case of
pipelined filters.  In the base case, consider that two filters are
connected, with the output of $A$ feeding the input of $B$.  We are
seeking $\ma{I_A}{O_B}(x)$: the maximum number of items that can
appear on tape $O_B$ given that there are $x$ items on tape $I_A$.
Observing that a maximum of $\ma{I_A}{O_A}(x)$ items can appear on
tape $O_A$, and that $O_A$ must equal $I_B$ since the filters are
connected, we see that a maximum of
$\ma{I_B}{O_B}(\ma{I_A}{O_A}(x))$ items can appear on $O_B$:
\begin{equation*}
\ma{I_A}{O_B} = \ma{I_B}{O_B} \circ \ma{I_A}{O_A}
\end{equation*}
In the case of $\mi{I_A}{O_B}(x)$, the order of composition is
reversed: given that there are $x$ items on tape $O_B$, a minimum of
$\mi{I_B}{O_B}(x)$ are on tape $I_B$, and since $O_B = I_A$, we have
that a minimum of $\mi{I_A}{O_A}(\mi{I_B}{O_B}(x))$ items appear on
$I_A$, leaving:
\begin{equation*}
\mi{I_A}{O_B} = \mi{I_A}{O_A} \circ \mi{I_B}{O_B}
\end{equation*}
By identical reasoning, these composition laws hold for pipelined
streams as well as filters.  That is, given tapes $x$, $y$, and $z$, 
we have that:
\begin{eqnarray}
\label{eq:compose}
\ma{x}{z} = \ma{y}{z} \circ \ma{x}{y} \\
\mi{x}{z} = \mi{x}{y} \circ \mi{y}{z}
\end{eqnarray}
However, there are some restrictions on these definitions.  They only
apply when there is a downstream path $P_1$ from the filter following
$x$ to the filter preceding $y$, a downstream path $P_2$ from the
filter following $y$ to the filter preceding $z$, and the paths $P_1$
and $P_2$ are non-overlapping.  This restriction prevents the
successive composition of transfer functions around feedback loops,
thereby ensuring a unique definition for all pairs $(x, z)$ where
there is a downstream path from $x$ to $z$.

\subsubsection{SplitJoins}

\begin{figure}
\centering
\psfig{figure=splitjoin.eps,width=3.2in}
\caption{\protect\small SplitJoin construct with labeling.
\protect\label{splitjoin}}
\end{figure}

We now derive $min$ and $max$ in the case of a SplitJoin, as pictured
in Figure \ref{splitjoin}.  For the splitter $S$ there are two output
tapes; let us denote them by $O1_S$ and $O2_S$.  Similarly, let us
denote the two input tapes of the joiner $J$ by $I1_J$ and $I2_J$.  We
now derive the transfer functions for round robin and
duplicate/combine nodes.  Note that the duplicate/combine nodes can be
simulated with round robins and duplicating filters, but we provide
the transfer functions anyways to simplify the semantic analysis of a
program.

{\bf Round robin splitter.}  In the case of a round-robin splitter, the
items from the input tape are alternately routed to the output tapes,
with the first item going onto tape $O1_S$.  By this definition, we
can see that the splitter's $max$ is defined as follows:
\begin{eqnarray*}
\ma{I_S}{O1_S}(x) = \left\lceil\frac{x}{2}\right\rceil \\
\ma{I_S}{O2_S}(x) = \left\lfloor\frac{x}{2}\right\rfloor
\end{eqnarray*}
To derive the $min$ function across a splitter, observe that the input
tape need only progress so far as to produce the items on the emptier
output tape.  That is, we need to consider the number of items on both
of the splitter's output to determine the minimum number of items that
are needed at its input.  Thus, our $min$ function has two arguments:
the first corresponding to $O1_S$ and the second corresponding to
$O2_S$.  The equation is as follows:
\begin{eqnarray*}
\mi{I_S}{(O1_S, O2_S)}(x_1, x_2) = MIN(2*x_1-1, 2*x_2)
\end{eqnarray*}
{\bf Round robin joiner.}  The rules for a round robin joiner are in
some sense dual to those of the round robin splitter.  Again assuming
that items are alternately drawn from the input tapes, starting with
$I1_J$, we have that:
\begin{eqnarray*}
\mi{I1_J}{O_J}(x) = \left\lceil\frac{x}{2}\right\rceil \\
\mi{I2_J}{O_J}(x) = \left\lfloor\frac{x}{2}\right\rfloor
\end{eqnarray*}
Again, the $max$ function takes two arguments, corresponding to the
number of items on $I1_J$ and $I2_J$, respectively:
\begin{eqnarray*}
\ma{(I1_J, I2_J)}{O_J}(x_1, x_2) = MIN(2*x_1-1, 2*x_2)
\end{eqnarray*}
{\bf Duplicate splitter}.  Clearly, the $max$ function of a duplicate
splitter is simply the identity function, since it maps each element
on the input tape to the same location on the output tapes:
\begin{eqnarray*}
\ma{I_S}{O1_S}(x) = x \\
\ma{I_S}{O2_S}(x) = x
\end{eqnarray*}
The $min$ function is similar, except that--like the round robin
split--the input need only progress as far as the lesser output:
\begin{eqnarray*}
\mi{I_S}{(O1_S, O2_S)}(x_1, x_2) = MIN(x_1, x_2)
\end{eqnarray*}
{\bf Combine joiner.} The combine joiner is simply the dual of the
duplicate splitter, with transfer functions that the reader can verify
as follows:
\begin{eqnarray*}
\ma{(I1_J, I2_J)}{O_J}(x_1, x_2) = MIN(x_1, x_2) \\
\mi{I1_J}{O_J}(x) = x \\
\mi{I2_J}{O_J}(x) = x
\end{eqnarray*}

\subsubsection{FeedbackLoops}

\begin{figure}
\centering
\psfig{figure=feedback.eps,width=3.2in}
\caption{\protect\small  FeedbackLoop construct with labeling.
\protect\label{looplabel}}
\end{figure}

We have to be careful when defining the transfer functions for
feedback loops (see Figure \ref{looplabel}).  The feedback splitter
$FS$ serves as a normal splitter, and has the same $min$ and $max$
functions as defined above.  However, the feedback joiner $FJ$ is
slightly different than a standard joiner, since during the first few
executions it fabricates values from the loop body before they appear
on the input tape.  The transfer function must take special account of
these initial values, since they never appear on $I2_{FJ}$, the input
tape from the loop body.  This is because we model the initialization
of FeedbackLoops by feeding the joiner the initial values directly
instead of pushing them onto a channel.

Let $n$ be the number of initial values that are provided to the
feedback joiner before values from the feedback loop are read.  Let
$J$ be a normal COMBINE or ROUND\_ROBIN joiner as defined for
SplitJoins.  Now, let us define the transfer functions for $FJ$, the
feedback joiner.

The $min$ function for the main stream is as before:
\begin{eqnarray*}
\mi{I1_{FJ}}{O_{FJ}} = \mi{I1_J}{O_J} 
\end{eqnarray*}
However, we must offset by $n$ when considering the $min$ function
that draws from the loop's tape:
\begin{eqnarray*}
\mi{I2_{FJ}}{O_{FJ}}(x) = \mi{I2_J}{O_J}(x) - n
\end{eqnarray*}
Finally, the $max$ function must be similarly shifted for the input
from the loop:
\begin{eqnarray*}
\ma{(I1_{FJ}, I2_{FJ})}{O_{FJ}}(x_1, x_2) = \ma{(I1_J, I2_J)}{O_J}(x_1,
x_2 + n)
\end{eqnarray*}

\subsubsection{Summary}

We have derived expressions for $\ma{a}{b}$ and $\mi{a}{b}$ for when
$a$ and $b$ are the respective input and output to 1) a filter, 2) a
pipeline, 3) a split or join, and 4) a feedback split or join.  By
composing these expressions following Equation~\ref{eq:compose}, we
can arrive at values of $\ma{a}{b}$ and $\mi{a}{b}$ for all pairs of
tapes $(a, b)$ where there is some directed path through the stream
graph--that is, along the direction of data flow--from the filter
reading from tape $a$ to the filter writing to tape $b$.

\subsection{Semantics}

Equipped with definitions of $\ma{a}{b}$ and $\mi{a}{b}$, we can now
address the semantics of StreaMIT's message delivery and latency
guarantees.

\subsubsection{Messages}

Suppose that filter $A$ sends a message to filter $B$ with latency
$n$, where $n$ is any integer.  In $n$ invocations of $A$'s {\tt work}
function, $A$ will produce one or more data items $d$.  Now, the
messaging system guarantees that:
\begin{enumerate}
\item If $B$ is upstream of $A$, then $B$ will receive the message
immediately following the last invocation of its {\tt work} function
which produces items that affect $d$.

\item If $B$ is downstream of $A$, then $B$ will receive the message
immediately preceding the first invocation of its {\tt work} function
which produces items that are effected by $d$.

\item If $B$ runs in parallel with $A$, then the message timing is in terms
of a shared set of splitters and joiners.  We are developing semantics
for this case, but they are beyond the scope of this paper.
\end{enumerate}
These guarantees can be expressed more formally as a set of
constraints on the number of items on certain tapes in the system.
Again, suppose that filter $A$ sends a message to filter $B$ with
latency $n$, where $n$ is any integer.  Let $s$ denote the number of
items on $O_A$ when the message was sent, and $r$ denote the number of
items on $O_B$ when the message is received.  We have that:

\begin{enumerate}

\item If $B$ is upstream of $A$, the message will be delivered when:
\begin{eqnarray}
\label{eq:msgup}
r = \mi{O_B}{O_A}(s + push_A * n)
\end{eqnarray}
That is, $s + push_A * n$ is the number of items on $A$'s output tape
after producing the data of interest.  Then, $y =
\mi{O_B}{O_A}(s + push_A * n)$ is the latest item on $B$'s output
tape that affects the data of interest.  The message should be
delivered immediately after the work function producing this item,
which occurs when the item count $r$ equals $y$, as specified by the
constraint.

\item If $B$ is downstream of $A$, the message will be delivered when:
\begin{eqnarray}
\label{eq:msgdown}
r = \ma{O_A}{O_B}(s + push_A * (n-1))
\end{eqnarray}
That is, $s + push_A * (n - 1)$ is the number of items on $A$'s
output tape before pushing the data of interest, and $y =
\ma{O_A}{O_B}(s + push_A * (n-1))$ is the maximum number of items
on $B$'s output tape as a result of the outputs of $A$.  Thus, when
$A$ pushes the next set of data, it could affect the data that will be
pushed next onto the output tape of $B$.  (Note that the next set of
data from $A$ might not be sufficient to calculate the next set on
$B$'s output, but it could affect it nonetheless.)  The message must
be delivered immediately before this effected data appears on $B$'s
output, so the number of items $r$ on $B$'s output must equal $y$.

\end{enumerate}

\subsubsection{Latency}

Each directive {\tt MAX\_LATENCY(A, B, n)} has the same effect as
defining a message from filter $B$ to upstream filter $A$ with latency
$n$.

\subsubsection{Scheduling}

We can fully define the possible sequences of filter executions as a
set of constraints on the number of items on each tape in the stream
graph.  This is useful not only from the perspective of semantics, but
for compiler analysis of the space of valid schedules.  We will use
$n(t)$ to represent the number of items on tape $t$ at a given point
of execution.  A configuration C of the stream graph can be completely
represented by the vector $(n(t_1), n(t_2), \dots, n(t_k))$, where
$t_1$ through $t_k$ are the tapes in the graph.  A legal configuration
must satisfy three sets of constraints:
\begin{enumerate}
\item {\it Data dependences.}  A filter can only have as many items on
its output tape as can be produced by the items on its input tape.
For each filter $A$ in the program, we have the constraint:
\begin{eqnarray*}
n(O_A) \le \ma{I_A}{O_A}(n(I_A))
\end{eqnarray*}
Equivalently, we can pose this constraint in the opposite direction:
each input tape must contain at least the number of items that are
required by the output tape:
\begin{eqnarray*}
n(I_A) \ge \mi{I_A}{O_A}(n(O_A))
\end{eqnarray*}
\item {\it Message guarantees.}  Suppose that a filter $A$ might send
a message to filter $B$ with a maximum latency of $l$ during any
invocation of its work function.  Then we must constrain the execution
of $B$ to make sure that it is not too far ahead to receive the
message with the given latency.  That is, we can only execute $B$ so
long as $n(O_B)$--the item count on its output tape--does not exceed
the count when a message would be delivered.  Recalling the expression
for message delivery time (Equations \ref{eq:msgup} and
\ref{eq:msgdown}), this constraint is as follows if $B$ is upstream of $A$:
\begin{eqnarray*}
n(O_B) \le \mi{O_B}{O_A}(n(O_A) + push_A * l)
\end{eqnarray*}
and as follows if $B$ is downstream of $A$:
\begin{eqnarray*}
n(O_B) \le \ma{O_A}{O_B}(n(O_A) + push_A * (n-1))
\end{eqnarray*}
\item {\it Latency guarantees.}  The guarantees for latency are
treated identically to message guarantees, as fitting with the
semantics of latency as described above.
\end{enumerate}
{\bf Defining the schedule.}  For a stream graph with a given set of
latency requirements and message delivery guarantees, we now have a
set of constraints expressing whether or not a given configuration
$(n(t_1), n(t_2), \dots, n(t_k))$ is legal.  It is a straightforward
step to formulate a legal sequence of transitions between
configurations, thereby exactly defining a legal order in which to
execute the filters' work functions.

When the program begins, no items have been pushed on any data
channels.  Thus, each tape is empty, and the starting configuration
$C_0$ is simply the zero-vector.  It is possible that the initial
configuration violates some of the constraints imposed by the
messaging and latency constructs, in which case the compiler can
inform the programmer that the delivery constraints requested in the
program are unsatisfiable.

Let {\cal P}(C) denote whether or not the constraints for a stream
graph are satisfied for a given configuration C.  We can then write
the transition function between configurations as follows:
\begin{eqnarray*}
(n(t_1), \dots , n(out_A), \dots, n(t_k)); \\ \frac{{\cal P}((n(t_1), \dots , n(out_A + push_A), \dots, n(t_k)))}{(n(t_1), \dots , n(out_A + push_A), \dots, n(t_k))}
\end{eqnarray*}
To understand this rule, observe that if we execute one step of filter
$A$, the only difference between the original configuration $C$ and
the new configuration $C'$ is that the item count for the output tape
of $A$ has increased by $push_A$ in $C'$.  Thus, if $C$ was valid and
$C'$ satisfies the constraints {\cal P}, then $C'$ represents a legal
configuration and the execution of $A$ is valid.  These operational
semantics are interesting in that we do not need to explicitly model
which data items are currently in which channels; instead, all of the
state is captured in terms of each filter's execution history.

\subsection{Program Verification}

A number of program analysis techniques are also enabled by the $min$
and $max$ functions that we have defined.  In particular, it is very
simple to compute 1) whether or not the program will deadlock as a
result of a starved input channel, and 2) whether or not any buffer
will grow without bound during the steady-state execution of the
program.

{\bf Deadlock detection.}  The deadlock detection algorithm takes
advantage of the fact that the only loops in our stream graph are part
of a FeedbackLoop construct.  A stream graph will be deadlock-free if
and only if there is no net change of output rate in the feedback
loop.  This can be formulated in terms of the $max$ function by
requiring that the wavefront from the output of the feedback joiner
$FJ$ unto itself is the identity function.  However, since we were
careful to leave the $max$ function undefined over cycles in the
stream graph, we define a new function $maxloop$ that maps a given
feedback joiner to the information wavefront around the loop:
\begin{eqnarray*}
\mal{FJ}(x) \equiv \ma{I2_FJ}{O_FJ} \circ \ma{O_FJ}{I2_FJ}
\end{eqnarray*}
The order of composition is as in Equation \ref{eq:compose} for the
composition of pipelines. Also, for the purposes of calculating
$\mal{FJ}$, one must assume that there are an infinite number of items
on tape $I1_FJ$; that is, the join from the feedback loop is not
limited by the external data source.  

Finally, we can state the constraint that the feedback loop must
respect.  For a loop with declared latency $n$, the loop will neither
overflow nor deadlock if:
\begin{eqnarray*}
\mal{FJ}(x) = x + n
\end{eqnarray*}
If $\mal{FJ}(x)$ is less than $x + n$, then there will be deadlock in
the program.

{\bf Overflow detection.}  There are two places that a buffer can
overflow in the stream graph.  The first is in a feedback loop, when
$\mal{FJ}(x)$ (calculated above) is more than $x + n$.  The second
case is when the parallel streams of a split/join have different
production rates.  For a splitter $S$ and a joiner $J$, the production
rates will cause an overflow if and only if $\ma{O1_S}{I1_J}(x) -
\ma{O2_S}{I2_J}(x)$ is not $O(1)$.  This difference could be analyzed
by a compiler for every SplitJoin in the stream graph to verify that
no buffers will overflow during steady-state execution.




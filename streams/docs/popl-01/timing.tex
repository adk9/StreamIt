\section{Timing Semantics}

In this section we develop a more formal semantics for the message
delivery guarantees described above.  The timing model in StreaMIT is
unique in that all time is relative to {\it information
wavefronts}--that is, two independent filters can describe a common time
only in terms of when the {\it effects} of one filter's execution are
seen by another.  Thus, although each filter's {\tt work} function is
invoked asynchronously without any notion of global time, two
invocations of a work function occur at the same ``information-relative
time'' if they operate on the same information wavefront.

To define this notion more precisely, we present transfer functions that
describe the flow of information across filters and streams.  Using
these transfer functions, we translate message delivery constraints into
a set of constraints on the execution schedule of the stream graph.
Finally, we use these scheduling constraints to formulate an operational
semantics for messaging, latency, and re-initialization in StreaMIT.

\subsection{Information Flow}

The concept of information flow is central to the streaming domain.
When an item enters a stream, it carries with it some new information.
As execution progresses, this information cascades through the stream,
effecting the state of filters and the values of new data items which
are produced.  We refer to an ``information wavefront'' as the sequence
of filter executions that first sees the effects of a given input item.
This wavefront is well-defined even in the presence of rate-changing
filters that peek, pop, and push differing number of items in each
invocation of their work function.

\begin{figure}[t]
\begin{verbatim}
Diagram of some filters connected by infinite tapes, marking the regions
that are were previously on the tape (but have been popped), the items
that are currently under consideration (for popping & peeking), and the
items that haven't shown up yet.  Similarly for pushing, somehow.  Maybe
show a cone collapsing a region of some input tape into the output tape,
labeling the regions.
\end{verbatim}
\vspace{-12pt}
\caption{\protect\small FIR / FFT Filters.
\vspace{-12pt}
\end{figure}

To formalize the wavefront, we introduce some new representations for
the state of the stream graph.  Consider that in place of each data
channel there is an infinite ``tape'' which contains the history of
values that have been pushed onto the channel.  For a given filter $A$,
let $in_A$ and $out_A$ denote the number of items appearing on its input
and output tapes, respectively, during a point of the stream's
execution.  Now consider the following functions:

\begin{itemize}

\item Given that there are $x$ items on the input tape of filter $A$,
the maximum number of items on the output tape of filter $B$ is
$f_{AB}(x)$.  That is, $f_{AB}(x) = max(out_B | in_A = x)$.

\item Given that there are $x$ items on the output tape of filter $B$,
the minimum number of items on the input tape of filter $A$ is
$g_{AB}(x)$.  That is, $g_{AB}(x) = min(in_A | out_B = x)$.

\end{itemize}

We now derive $f_AB$ and $g_AB$ for certain pairs of nodes $(A, B)$ in
the stream graph.  Doing so will allow us to express the semantics of
messaging, latency, and re-initialization.

\subsubsection{Filters}

Consider a filter $A$ that peeks $peek_A$, pops $pop_A$, and pushes
$push_A$ data items on every execution step.  To derive $f_AA(x)$,
observe that the filter can execute so long as it does not peek beyond
the $x$'th item on the input tape.  After the $n$'th execution, it has
popped $n$ items, peeked up to $n + (peek_A - pop_A)$, and popped $2 *
n$ items.  Thus, it can execute $n = floor((x - (peek_A - pop_A)) /
pop_A))$ times, leaving the following expression for $f_AA(x)$:
\begin{eqnarray*}
f_{AA}(x)&= push_A*floor((x-(peek_A-pop_A))/pop_A) if x \ge (peek_A-pop_A) \\
         &= push_A*floor((x-(peek_A-pop_A))/pop_A) if x <  (peek_A-pop_A)
\end{eqnarray*}
Similarly, the reader can verify that:
\begin{eqnarray*}
g_{AA}(x)&= ceil(x/push_A)*pop+(peek_A-pop_A)
\end{eqnarray*}

\subsubsection{Pipelines}


--------------------------------------------------------------------------

- Definition of wavefront stuff

- Scheduling Constraints
	- data flow
	- messaging

- Semantics of the functions
	- in terms of messages and latency

\begin{verbatim}

let's try some new definitions:

given that there are exactly x items on your input tape, the maximum
number of items you can have on your output tape is h(x)

the inverse is now well-defined: given that there are exactly x items
on your output tape, the minimum number of items you need on your
input tape is p(x)

filter:		h(x) = push*max(0, floor((x-(peek-pop))/pop))
split:		h(x) = (ceil(x/2), floor(x/2))
join:		h(x1, x2) = min(2*x1-1, 2*x2)

filter:		p(x) = ceil(x/push)*pop+(peek-pop)
split:		p(x1, x2) = min(2*x1-1, 2*x2)
join:		p(x) = (ceil(x/2), floor(x/2))

--

scheduling constraints:

- again let n_a denote the number of items on the OUTPUT tape of filter a

if have filters a and b in pipeline (a -> b), then these are equivalent:
	- n_b <= h_b(n_a)
	- n_a >= p_b(n_b)

if have splitjoin with input a, then (b, c) in parallel, and output d:
	- there are n_a on input
	- can have up to h(n_a) = (ceil(n_a/2), floor(n_a/2)) into (b, c)
	- can have up to (h_b(ceil(n_a/2)), h_c(floor(n_a/2))) out of (b, c)
	- can have up to min(2*h_b(ceil(n_a/2))-1,2*h_c(floor(n_a/2))) into d

	so constraint is that:
	- n_d <= h_d( min(2*h_b(ceil(n_a/2))-1,2*h_c(floor(n_a/2))) )

	or, in other words, h(x) for a split/join is:
		h(x) = min(2*h_b(ceil(n_a/2))-1,2*h_c(floor(n_a/2)))

if sending message from a to b with max wavefront latency n, then:
	
	1. if b is downstream, with filters x1, x2, x3 in between a and b:
			a -> x1 -> x2 -> x3 -> b

		n_b <= h_b(h_x3(h_x2(h_x1(n_a + n * a.push))))

	2. if b is upstream, with filters x1, x2, x3 between b and a:
			b -> x1 -> x2 -> x3 -> a

		n_b <= p_x3(p_x2(p_x1(p_a(n_a + n * a.push))))

	3. in the general case, a is sending message to b.  trace a
		path, finding y1, y2, y3 that are blocks between OUTPUT of
		a and OUTPUT of b.  a -> y1 -> y2 -> y3 -> b.  (note that
		if b is upstream, then y1 = a.)  Then we have:

		n_b <= z_y3(z_y2(z_y1(n_ a + n * a.push)))

		where z is replaced by h if we are traveling downstream, 
		but replaced by p if we are traveling upstream.

aha, if coming from common sender or going to common receiver, the wavefront
	must have EQUAL index at the sender or receiver.  so you REFLECT
	around split/join points instead of translating through them.
	because if you go up one part of join and down the other, the
	wavefront shifts

\end{verbatim}


\section{Applications}

\subsection{Node-Level Optimization}

Perhaps the most immediate application of our technique is to use the
SARE representation to bridge the gap between intra-node dependences
and inter-node dependences.  Our presentation in the last section was
in terms of a coarse-grained work function $W$ mapping inputs to
outputs.  However, if the source code is available for the node, then
the equations containing $W$ can be expanded into another level of
affine recurrences that represent the implementation of the node
itself.  (If the node contained only static control flow, then this
formulation as a SARE would be exact; otherwise, one could use a
conservative approximation of the dependences.)

The resulting SARE would expose the fine-grained dependences between
local variables of a given node with the local variables of
neighboring nodes.  We believe that this information opens the door
for a wide range of novel node optimizations, which we outline in the
following sections.

\subsubsection{Inter-Node Dataflow Optimizations}

Once the SARE has exposed the flow dependences between the internal
variables of two different nodes, one can perform all of the classical
dataflow optimizations as if the variables were placed in the same
node to begin with.  For instance, constant propagation, copy
propagation, common sub-expression elimination, and dead code
elimination can all be performed throughout the internals of the nodes
as if they were connected in a single control flow graph.

Some of these optimizations could have a very large performance
impact; for instance, consider a 2:1 downsampler node that simply
discards half of its input.  Using the SARE, it is straightforward to
trace the element-wise dependence chain from each discarded item, and
to mark each source operation as dead code (assuming the code has no
other consumers.)  In this way, one can perform fine-grained
decimation propagation throughout the entire graph and prevent the
computation of any items that are not needed.  This degree of
optimization is not possible in frameworks that treat the node as a
black box.

\subsubsection{Steady-State Invariant Code Motion}

In the streaming domain, the analog of loop-invariant code motion is
the motion of code from the steady-state epoch to the initialization
epoch if it does not depend on any quantity that is changing during
the steady-state execution of a node.  Quantities that the compiler
detects to be constant during the execution of a work function can be
computed from the initialization epoch, with the results being passed
through a feedback loop for availability on future executions of work.

\subsubsection{Fission Transformations}

It may be the case that many of the operations that are grouped within
a node are completely independent, and that the node can be split into
sub-components that can execute in parallel or as part of a more
fine-grained schedule.  For instance, many operations using complex
data types are grouped together from the programmer's view, even
though the operations on the real and imaginary parts are completely
separate.  Given a SARE representation of the graph and the node, this
``node fission'' is completely automatic, as there would be no
dependence between the operations in the SARE.  A scheduling pass
would treat the real and imaginary operations as if they were written
in two different nodes to begin with.

\subsubsection{Induction Variable Detection}

SAMAN HERE'S HOW FAR I AM

The {\tt work} function can also be analyzed as would the body of a loop
to see if there are induction variables from one steady-state execution
to the next.  This analysis is useful both for strength reduction, which
{\it adds} a dependence between invocations by converting an expensive
operation to a cheaper, incremental one, as well as for data
parallelization, which {\it removes} a dependence from one invocation to
the next by changing incremental operations on filter state to
equivalent operations on privatized variables.

\subsection{Parameterized Graphs}

Don't need to duplicate code for nodes that are repeated.  Can also
parameterize the schedule along these dimensions.  Especially
well-tailored to StreamIt.  Compare to PSDF.

\subsection{Graph-Level Optimization}

Attractive because there's a unified mathematical model for expressing
constraints.

\subsubsection{Scheduling}

Perhaps most attractive feature, as there is a large body of work on
scheduling and automatic parallelization for affine dependences
(lim/lam, feautrier, darte/vivien etc.)  It can identify what filters
can run in parallel, and optimize for different metrics
(synchronization, communication, etc.)  Hasn't been addressed as
thoroughly in the SDF community.

Also scheduling for other optimization metrics is interesting.

\subsubsection{Buffer Minimization}

Data buffer size is important to the DSP community.  There's a large
body of work on minimizing buffer requirements in their community as
well as in the scientific community.  This lets the results of the
whole scientific community apply to the dataflow community.

Not just scheduling - also collapsing, reusing, detecting live ranges,
sharing buffers, etc.

\subsubsection{Code Size}

Cody size is also very important.  While this has perhaps received
less attention in the context of SARE's, there are interesting
advantages that affine scheduling could offer to the DSP community.
For instance, most DSP schedules abide by a ``single appearance
schedule'' where the execution of each filter is in a perfect loop
nest.  However, often times an affine schedule will lead to a case
where a filter is nested in a given loop, but only executes on every
other invocation; it's execution is governed by a conditional.  To our
knowledge, this kind of schedule hasn't been explored by the DSP
community, and could be promising.

Also not just scheduling - how do you arrange things.

\subsubsection{Partitioning}

Provides a good framework for distributing a streaming computation
across an architecture.

%% \subsection{Verification}

%% Buffer overrun, no exploding schedules, etc.

%% \subsection{Semantics of Time}

%% \noindent {\bf \dep}

%% \begin{align*}
%% \DEP{X}{Y}(i) = max_{\preceq}~\{~ j ~|~ \exists ~&~ T_0 \dots T_n, ~ k_0 \dots k_n, ~ {\cal E}_1 \dots {\cal E}_n ~ s.t. ~ & ~ \\ 
%% ~ & T_0 = Y ~\wedge~ T_n = X ~\wedge~ k_0 = j ~\wedge~ k_n = i ~\wedge~ & ~ \\
%% ~ & \forall p \in 1 \dots n, ~ T_p(k_p) \equiv f_{{\cal E}_p}(\dots, T_{p-1}(h_{{{\cal E}_p}, T_{p-1}}(k_p)), \dots) ~ \} & ~ \\
%% \end{align*}

%% In StreamIt, this function is composable because of single-input,
%% single-output blocks.  Since every junction is a one-dimensional
%% array, it gives unique point in time for a given filter.  Can use this
%% to think modularly/composably about time in components, too.

%% Describe messaging semantics?  Is there space?

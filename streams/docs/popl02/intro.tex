\section{Introduction}

Synchronous dataflow graphs have become a powerful and widespread
programming abstraction for DSP environments.  Originally proposed by
Lee and Messerchmitt in 1987~\cite{LM87-i}, synchronous dataflow has
since evolved into a number of
varieties~\cite{BELP96,Bhatt00,Murthy2002,Buck93} which provide a
natural framework for developing modular processing blocks and
composing them into a concurrent network.  A dataflow graph consists
of a set of nodes with channels running between them; data values are
passed as streams over the channels.  The {\it synchronous} assumption
is that a node will not fire until all of its inputs are ready.  Also,
the input/output rates of the nodes are known at compile time, such
that a static schedule can be computed for the steady-state execution.
Synchronous dataflow graphs have been shown to successfully model a
large class of DSP applications, including speech coding,
auto-correlation, voice band modulation, and a number of filters.  A
significant industry has emerged to provide dataflow design
environments; leading products include COSSAP from Synopsys, SPW from
Cadence, ADS from Hewlett Packard, and DSP Station from Mentor
Graphics.

Optimization is especially important for signal processing
applications, as embedded processors often have tight resource
constraints on speed, memory, and power.  In the synchronous dataflow
domain, this has resulted in a number of aggressive optimizations that
are specially designed to operate on dataflow graphs--e.g., minimizing
buffer size while restricting code size~\cite{murt1997x1}, minimizing
buffer size while maintaining parallelism~\cite{GGD94},
resynchronization~\cite{Bhatta2000}, and buffer
sharing~\cite{murt2001x1}.  While these optimizations are beneficial,
they unilaterally regard each node as a black box that is invisible to
the compiler.  Blocks are programmed at a coarse level of granularity,
often with hand-tweaked implementations inside, and optimizations are
considered only when stiching the blocks together.

In some sense at the other end of the spectrum are the optimization
techniques of the scientific computing community.  These are
characterized by fine-grained analyses of loops, statements, and
control flow, starting from intricate source code that lacks the
explicit parallelism and communication of a dataflow graph.  Out of
this community has come a number of general methods for precise,
fine-grained program analysis and optimization.  In the context of
array dataflow analysis and automatic parallelization, one such
technique is affine scheduling; in recent years, it has been shown
that affine dependences can exactly represent the flow dependences in
certain classes of programs~\cite{Feautrier92i}, and that affine
partitioning can subsume loop fusion, reversal, permutation, and
reindexing as a scheduling technique~\cite{Lim98}.  Moreover, affine
scheduling can operate on a parameterized version of the input
program, avoiding the need to expand a graph for varying parameters
and problem sizes, and it can often reduce to a linear program for
flexible and efficient optimization.  Affine representations have also
been utilized for storage optimization~\cite{Lim01,Quillere,Thies01}.

In this paper, we aim to bridge the gap and bring to bear the affine
analysis techniques of the scientific community on the synchronous
dataflow graphs of the DSP community.  Towards this end, we present a
translation from a dataflow graph to a System of Affine Recurrence
Equations (SARE), which are equivalent to a certain class of
imperative programs and can be used as input to the affine analysis
described above.  The input of our analysis is a ``Phased Computation
Graph'' (PCG), which we formalize as a generalization of several
existing dataflow frameworks.  Once a PCG is represented as a SARE, we
demonstrate how affine techniques could be employed to perform novel
optimizations such as node splitting, decimation propagation, and
steady-state invariant code motion that exploit both the structure of
the dataflow graph as well as the internal contents of each node.  We
also discuss the potential of affine techniques for scheduling
parameterized dataflow graphs, as well as offering new approaches to
classic problems in the dataflow domain.

The rest of this paper is organized as follows. \todo{fill this in}
